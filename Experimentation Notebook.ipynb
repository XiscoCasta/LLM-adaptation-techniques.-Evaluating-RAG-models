{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee85def-595b-47bc-a2fb-aea034ad124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datasets import Dataset,load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.schema import Document\n",
    "from functions import CustomHuggingFaceEmbeddings, GenerativePipeline, tokenize_compare, RAGPipeline, split_documents, evaluate_vector_databases, evaluate_answers, RAGPipeline_with_rerank\n",
    "import faiss\n",
    "def embedding_function(text):\n",
    "    return embedding_model_1.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88bb4977-d3cc-4d97-af2f-ef7182681a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag to choose between generating all answers and databases or load them from the disk\n",
    "Generating = True\n",
    "#In case of generating them, flag to choose between saving them on the disk or not.\n",
    "Saving = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c68a34-ed06-41c5-87ee-5f185aa355fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"PKL files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44119407-c989-49cd-bf54-f24f39279982",
   "metadata": {},
   "source": [
    "# First experiment. Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17904c2-db3b-40f4-8b0c-27f432b09b2c",
   "metadata": {},
   "source": [
    "We will use the SQuAD dataset, which contains paired question-context data. We will use its validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2b502a-4a96-49bc-802f-665ae59598c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a19b08-f200-4e20-b46e-21315ace981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76c72c-241b-4e9a-be56-b77e58b3ca8a",
   "metadata": {},
   "source": [
    "We will not split the documents, as they are already short context documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f484e1-e1cd-403b-b365-8d7da78fab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f8911a-2ff6-4f77-b189-d22b135be012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aeea6420ada46c2ab3f703531ce9af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70868961-b258-4ec8-a182-43ef30a16d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3d62856c744c0f943a6985b11f66c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb784be7-da7c-4c25-a171-f8f2a316b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2067"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a2a99-5b61-4053-8883-3275949c7a56",
   "metadata": {},
   "source": [
    "As there is only 2067 unique contexts, I will extract a question randomly for each context, and examine which vector database gets better result with the different similarity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "118b71e0-c06b-4ca9-885d-2fbf07c196e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [doc.metadata['id'] for doc in docs_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd108176-dce6-464a-9034-4e683ea67e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465f647-ee12-4335-9960-c19f03df492f",
   "metadata": {},
   "source": [
    "Once converted to LangChain documents, just embed them into a vector database with different similarity metrics. The first model used will be NoInstruct small Embedding v0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91d9fb09-743f-493a-8440-2ce1e93a9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ceb249-7301-4dec-b20d-a4c8e3c93565",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_1.pkl', 'rb') as f:\n",
    "        VDB_l2_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7397b057-a20d-40c5-8e1c-7684e3bd2902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_1.pkl', 'rb') as f:\n",
    "        VDB_dot_product_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c6e6dd5-9bec-47ab-b6dd-c6f23fde7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_1.pkl', 'rb') as f:\n",
    "        VDB_cosine_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0744c6c0-fc52-41b9-8d8c-4398a70c7f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [22:26<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_1       0.721335  0.830189  0.876149  0.923077  0.959361  0.981616\n",
       "VDB_dot_product_1  0.721335  0.830189  0.876149  0.923077  0.959361  0.981616\n",
       "VDB_l2_1           0.721335  0.830189  0.876149  0.923077  0.959361  0.981616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Define the databases and their names\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_1\": VDB_cosine_1,\n",
    "    \"VDB_l2_1\": VDB_l2_1,\n",
    "    \"VDB_dot_product_1\": VDB_dot_product_1,\n",
    "}\n",
    "# Define the k values\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table1 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  # Calculate mean to get the proportion of `True` (True = 1, False = 0)\n",
    "    .unstack()  # Convert 'k' into columns\n",
    ")\n",
    "pivot_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cab203-59b6-42a8-8c0f-5925b41f2206",
   "metadata": {},
   "source": [
    "Repeat for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcf73204-744c-49cd-bc7a-5174249af282",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME2 = \"mavihsrr/bge-small-retail-finetuned\"\n",
    "embedding_model_2 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9435a9-164f-41ab-be6d-88d1b1d72b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_2 = FAISS.from_documents(docs_processed, embedding_model_2,distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_2.pkl', 'rb') as f:\n",
    "        VDB_l2_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7befd66-cde5-4f6e-a55b-554fcf910217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_2 = FAISS.from_documents(docs_processed, embedding_model_2, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_2.pkl', 'rb') as f:\n",
    "        VDB_dot_product_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "428f3c3b-346d-4eb8-9101-c262e9203a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_2 = FAISS.from_documents(docs_processed, embedding_model_2, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_2.pkl', 'rb') as f:\n",
    "        VDB_cosine_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "959af461-558d-4b4b-953e-957bd0ae80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [20:47<00:00,  1.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_2       0.728592  0.828737  0.874214  0.920174  0.955007  0.981132\n",
       "VDB_dot_product_2  0.728592  0.828737  0.874214  0.920174  0.955007  0.981132\n",
       "VDB_l2_2           0.728592  0.828737  0.874214  0.920174  0.955007  0.981132"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the databases and their names\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_2\": VDB_cosine_2,\n",
    "    \"VDB_l2_2\": VDB_l2_2,\n",
    "    \"VDB_dot_product_2\": VDB_dot_product_2,\n",
    "}\n",
    "\n",
    "# Define the k values\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table2 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  \n",
    "    .unstack()\n",
    ")\n",
    "pivot_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7f59d3-895e-48a9-9431-86ff3572279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-s and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME3 = \"Snowflake/snowflake-arctic-embed-s\"\n",
    "embedding_model_3 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8b090bf-3fd3-48ca-a080-f4204a97d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_3 = FAISS.from_documents(docs_processed, embedding_model_3,distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_3.pkl', 'rb') as f:\n",
    "        VDB_l2_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fdc8c36-e446-4f8e-90d8-d5262ef62955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_3 = FAISS.from_documents(docs_processed, embedding_model_3, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_3.pkl', 'rb') as f:\n",
    "        VDB_dot_product_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c1a159f-d58c-45e0-8348-0ff01dfc642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_3 = FAISS.from_documents(docs_processed, embedding_model_3, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_3.pkl', 'rb') as f:\n",
    "        VDB_cosine_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a1fd7ed-2b9e-4b1f-bd6d-b1685777321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [16:41<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_3       0.583938  0.707305  0.769231  0.823416  0.893566  0.936139\n",
       "VDB_dot_product_3  0.583938  0.707305  0.769231  0.823416  0.893566  0.936139\n",
       "VDB_l2_3           0.583938  0.707305  0.769231  0.823416  0.893566  0.936139"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the databases and their names\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_3\": VDB_cosine_3,\n",
    "    \"VDB_l2_3\": VDB_l2_3,\n",
    "    \"VDB_dot_product_3\": VDB_dot_product_3,\n",
    "}\n",
    "\n",
    "# Define the k values\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table3 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  # Calculate mean to get the proportion of `True` (True = 1, False = 0)\n",
    "    .unstack()  # Convert 'k' into columns\n",
    ")\n",
    "pivot_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b589d1-9bda-4565-bce7-dab66bf33078",
   "metadata": {},
   "source": [
    "# Second experiment. Baseline, contexted and RAG models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db4a39e5-a6d2-4d81-802a-5bce06bed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativePipeline()\n",
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3835a6ab-3076-4acb-9f8b-e64f79a7fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    baseline_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = model.generate_answer(question, context=\"\")  # Empty context\n",
    "        baseline_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths': subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/baseline_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(baseline_answers, f)\n",
    "else:\n",
    "    with open('PKL files/baseline_answers.pkl', 'rb') as f:\n",
    "        baseline_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86df60ee-bcbf-4847-813e-4e470aff0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    contexted_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        context = subset[i]['context']\n",
    "        answer = model.generate_answer(question,context)\n",
    "        contexted_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/contexted_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(contexted_answers, f)\n",
    "else:\n",
    "    with open('PKL files/contexted_answers.pkl', 'rb') as f:\n",
    "        contexted_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4794bbf9-8c65-4bef-8cf9-25ca6dd3bded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64b8e0f6af1403cb86dc72313e4c65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for baseline model:\n",
      "37 / 2067\n",
      "Exact Match Score: 0.0179\n"
     ]
    }
   ],
   "source": [
    "exact_matches,errors = evaluate_answers(baseline_answers,tokenizer,return_errors = True)\n",
    "# Print results\n",
    "print('Evaluation score for baseline model:')\n",
    "print(f\"{exact_matches} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b38d3191-b45f-4701-900d-aab475652dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bded742bda9d433ca1a2d8cf0970b54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for model with correct context:\n",
      "1438 / 2067\n",
      "Exact Match Score: 0.6957\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Exact Matches with Tokenization\n",
    "exact_matches_2 = evaluate_answers(contexted_answers, tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for model with correct context:')\n",
    "print(f\"{exact_matches_2} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_2 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f635d0f-4952-4585-889d-0d99fd443e8c",
   "metadata": {},
   "source": [
    "Maximum expected. Let's see RAG. We use VDB_l2_1 and VDB_l2_2 depending on the k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec019bb0-a546-4b10-9ab2-fc22a384981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_2,\n",
    "        retriever_kgt1=VDB_l2_1,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70162077-c5d8-4bcf-a592-b901f5b8a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        rag_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers.pkl', 'rb') as f:\n",
    "        rag_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "545572d7-6d2e-4fbf-8504-9878322ccffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        rag_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers_2.pkl', 'rb') as f:\n",
    "        rag_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f760871-c141-468c-a2ad-1044dd80315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        rag_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers_3.pkl', 'rb') as f:\n",
    "        rag_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b1693c-3ce8-4ecc-a812-8e6192c84fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b4fed80c774d3ebf0c652c3c09bb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "1082 / 2067\n",
      "Exact Match Score: 0.5235\n"
     ]
    }
   ],
   "source": [
    "exact_matches_3 = evaluate_answers(rag_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_3} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_3 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cdb6d570-9e14-4d06-87bb-dc5edae1ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f685854b3124208a781a37d4a5c5519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k=2:\n",
      "1165 / 2067\n",
      "Exact Match Score: 0.5636\n"
     ]
    }
   ],
   "source": [
    "exact_matches_4 = evaluate_answers(rag_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k=2:')\n",
    "print(f\"{exact_matches_4} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_4 / 2067:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "109ad974-0427-4964-ace7-e02aef59cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b47e4afb8142d5a50b944e0cd86b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k=3:\n",
      "1163 / 2067\n",
      "Exact Match Score: 0.5627\n"
     ]
    }
   ],
   "source": [
    "exact_matches_5 = evaluate_answers(rag_answers_3,tokenizer)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k=3:')\n",
    "print(f\"{exact_matches_5} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_5 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb55340-a89c-499c-9ba1-f67ae0c8c91d",
   "metadata": {},
   "source": [
    "# Natural questions from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "822b4696-ba49-4325-94ca-ae7a02701e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e082a9c1-39a4-452e-a594-fbc3d596c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef4a49a3e014ef7ba5105e8a94bdc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream the validation split of TriviaQA (rc.wikipedia.nocontext configuration)\n",
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\", streaming=True)\n",
    "\n",
    "# Collect the first 1000 entries\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "\n",
    "# Convert the list to a Hugging Face Dataset\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bda410d3-aac4-4323-a4a0-e44bed36b8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which Lloyd Webber musical premiered in the US on 10th December 1993?'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0]['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbae74-8cdd-4d15-b454-49b3d49a18b3",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2357b72-a9bd-466c-b8ef-0e9eb50201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativePipeline()\n",
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7077ccd-94a0-45ad-9c74-11b2651df084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    baseline_triviaqa_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = model.generate_answer(question, context=\"\")  # Empty context\n",
    "        baseline_triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths': subset[i][\"answer\"]['aliases']})\n",
    "    if Saving:\n",
    "        with open('PKL files/baseline_triviaqa_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(baseline_triviaqa_answers, f)\n",
    "else:\n",
    "    with open('PKL files/baseline_triviaqa_answers.pkl', 'rb') as f:\n",
    "        baseline_triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acb54c97-19df-4d11-ac05-357985d598e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1cefff97854bd484a9e31bd69607c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for baseline model:\n",
      "70 / 1000\n",
      "Exact Match Score: 0.0700\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_baseline = evaluate_answers(baseline_triviaqa_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for baseline model:')\n",
    "print(f\"{matches_triviaqa_baseline} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_baseline / 1000:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7739bb-c112-4a9b-b882-5ca2bcea969d",
   "metadata": {},
   "source": [
    "## Extracting actual Contexts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdaabb69-4787-4182-85f6-43838e30cbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1c70293c45418f87cec8364535604b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n"
     ]
    }
   ],
   "source": [
    "suma = 0\n",
    "for doc in tqdm(subset['entity_pages']):\n",
    "    suma += len(doc[\"wiki_context\"])\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb3d5dcb-ad1b-4ee2-9c80-35e5494ed395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee94bd1c9a9480aba3f448367c2cc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entity pages:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LangchainDocument objects created (after deduplication): 1537\n"
     ]
    }
   ],
   "source": [
    "Raw_contexts = []\n",
    "\n",
    "unique_contents = set()\n",
    "\n",
    "for entry in tqdm(subset, desc=\"Processing entity pages\"):\n",
    "        entity_pages = entry[\"entity_pages\"]\n",
    "        for i, context in enumerate(entity_pages[\"wiki_context\"]):\n",
    "            if context not in unique_contents:\n",
    "                unique_contents.add(context)\n",
    "                Raw_contexts.append(\n",
    "                    LangchainDocument(\n",
    "                        page_content=context,\n",
    "                        metadata={\n",
    "                            \"title\": entity_pages[\"title\"][i],\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Total LangchainDocument objects created (after deduplication): {len(Raw_contexts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfabfa-622d-41ca-a8b5-4624a854b021",
   "metadata": {},
   "source": [
    "There is a total of 1717 contexts, and when deleting the duplicates there is 1537."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0e8db9c-5460-4a53-a926-fd3c2e1b9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0688d55-ea24-42ad-938e-694a57364bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Raw_contexts,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "        docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee368ade-43c4-48c3-8a94-87251508f743",
   "metadata": {},
   "source": [
    "Next cell is done by batches and requires saving always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8260e067-5de8-40a9-85b7-481b4a0a1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 20000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e03d0b0-b3d9-4dff-abb2-0b0d733a7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (111999, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55c1c6c6-8eba-425d-b60f-35065c42eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    index.add(embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_contexts = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_contexts.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_contexts, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_contexts.pkl\", \"rb\") as f:\n",
    "        VDB_l2_contexts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a77f452-f299-4ade-ac85-68d1d6e690df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_contexts,\n",
    "        retriever_kgt1=VDB_l2_contexts,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dea5a8ef-bb1f-4850-80cc-e89ffd0b4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers.pkl', 'rb') as f:\n",
    "        triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4686b9b-5250-4475-830e-ed3ff5bc0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        triviaqa_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30a6a64f-ddd4-4e14-96f6-8fc990cb9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        triviaqa_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e766c10e-ab60-4bfa-a6b7-770af4a6a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_4 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=4,return_context = True)\n",
    "        triviaqa_answers_4.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_4.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_4, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_4.pkl', 'rb') as f:\n",
    "        triviaqa_answers_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3a5a8bd-59f8-4a9d-b2d3-83d5e3fd25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_5 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=5,return_context = True)\n",
    "        triviaqa_answers_5.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_5.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_5, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_5.pkl', 'rb') as f:\n",
    "        triviaqa_answers_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "560095f6-31d9-45f9-bcb9-05480bbff864",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_6 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=6,return_context = True)\n",
    "        triviaqa_answers_6.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_6.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_6, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_6.pkl', 'rb') as f:\n",
    "        triviaqa_answers_6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "19822f55-fead-4426-b266-56b211f17018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd20ba2d0a2043c98cc5c3a33eaf5daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "384 / 1000\n",
      "Exact Match Score: 0.3840\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa = evaluate_answers(triviaqa_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{matches_triviaqa} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7fcace7-eee5-41e8-ab12-8099fecf34ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6650359dec3a412aaf02fb838e385cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "457 / 1000\n",
      "Exact Match Score: 0.4570\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_2 = evaluate_answers(triviaqa_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{matches_triviaqa_2} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7823bcff-f341-47d5-80cd-fa9ae88d8d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f6c6a9b7574f12983c337c18924644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "476 / 1000\n",
      "Exact Match Score: 0.4760\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_3 = evaluate_answers(triviaqa_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{matches_triviaqa_3} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df5d8dac-3db8-4322-b0af-e4305d5724d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b0a4e87bcc4e74a792015701d66268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 4:\n",
      "487 / 1000\n",
      "Exact Match Score: 0.4870\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_4 = evaluate_answers(triviaqa_answers_4,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 4:')\n",
    "print(f\"{matches_triviaqa_4} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_4 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2faffb1b-fc8d-4aac-b651-c29d98a08a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd72b54ec2a648579d3076591c733169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 5:\n",
      "478 / 1000\n",
      "Exact Match Score: 0.4780\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_5 = evaluate_answers(triviaqa_answers_5,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 5:')\n",
    "print(f\"{matches_triviaqa_5} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_5 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f82f936-11a2-45f5-8d35-76f7bee8b425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2cb71c2050417faf1c7902e81e208a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 6:\n",
      "475 / 1000\n",
      "Exact Match Score: 0.4750\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_6 = evaluate_answers(triviaqa_answers_6,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 6:')\n",
    "print(f\"{matches_triviaqa_6} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_6 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522cc4a-c104-4832-9d11-ae4a0620363d",
   "metadata": {},
   "source": [
    "## Additional wikipedia passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af15169-3d2c-468d-8f7e-31df992082d0",
   "metadata": {},
   "source": [
    "We add wikipedia passages to go to a more real case, where we have additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9c5aa64-6bb2-4e35-b8c8-6ee69b1d38a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7bd48893-2d7f-4b17-87a2-ae23f4cdf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e1f13eac764959ae88b471a1ed9467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Additional_documents = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6a69e00-e291-4f2a-b4d8-8d1dbd6742be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed_2 = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Additional_documents,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed_2, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed_2.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed_2, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed_2.pkl\", \"rb\") as f:\n",
    "        docs_processed_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2afe0d66-5ecf-4832-9d57-d691c39554cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings_2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 100000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41cb9690-ccbd-46e4-b247-339598d45631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings_2\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings_2 = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings_2.shape}\")\n",
    "embeddings_2 = embeddings_2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4bc7b485-1307-42fe-947e-e567b6ad78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    all_embeddings = np.concatenate([embeddings, embeddings_2]).astype(np.float32)\n",
    "    index.add(all_embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    all_docs = docs_processed + docs_processed_2\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(all_docs)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_noisy = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_noisy.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_noisy, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_noisy.pkl\", \"rb\") as f:\n",
    "        VDB_l2_noisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "613168c5-baa7-49ab-a8bb-53d89d65c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_noisy,\n",
    "        retriever_kgt1=VDB_l2_noisy,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "364ed139-397a-459e-bd88-3c47dab75d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        triviaqa_noisy_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f44ce7e1-9359-49f0-bddb-754be5128642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        triviaqa_noisy_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "834d1289-d2bd-4eea-ad15-1d4de1d8111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        triviaqa_noisy_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9877518e-4273-48bb-93f4-132d1fd6a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_4 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=4,return_context = True)\n",
    "        triviaqa_noisy_answers_4.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_4.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_4, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_4.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd930428-982b-453a-9bab-b62910eb9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_5 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=5,return_context = True)\n",
    "        triviaqa_noisy_answers_5.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_5.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_5, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_5.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33af9475-9b37-448c-9ef8-38bd5044d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_6 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=6,return_context = True)\n",
    "        triviaqa_noisy_answers_6.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_6.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_6, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_6.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "faecc053-17c4-4625-af16-4b7b5127f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550245c11adf453b80d0b13caeb28fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "399 / 1000\n",
      "Exact Match Score: 0.3990\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa = evaluate_answers(triviaqa_noisy_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{matches_triviaqa} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "beab4911-256d-4de9-8002-ade0324a28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c42eaa44904c228abf9e49663eae1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "463 / 1000\n",
      "Exact Match Score: 0.4630\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_2 = evaluate_answers(triviaqa_noisy_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{matches_triviaqa_2} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80eedddf-dfb5-492c-b25b-90368b2c5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbf9e9a14af474a92e99f2fac84f79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "487 / 1000\n",
      "Exact Match Score: 0.4870\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_3 = evaluate_answers(triviaqa_noisy_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{matches_triviaqa_3} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4875b6a8-3b59-43a9-a44e-dbedf9b3ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd62ecf205224208b59cb7e17334f564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 4:\n",
      "500 / 1000\n",
      "Exact Match Score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_4 = evaluate_answers(triviaqa_noisy_answers_4,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 4:')\n",
    "print(f\"{matches_triviaqa_4} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_4 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ed0282f-a994-4a9a-b02a-1af9df91a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d7e465dcd24fd29cc269b5e269ffa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 5:\n",
      "496 / 1000\n",
      "Exact Match Score: 0.4960\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_5 = evaluate_answers(triviaqa_noisy_answers_5,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 5:')\n",
    "print(f\"{matches_triviaqa_5} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_5 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d056da6c-ec72-4444-8a58-edde383f7f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296363f944d24395a9bfccca0169a100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 6:\n",
      "493 / 1000\n",
      "Exact Match Score: 0.4930\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_6 = evaluate_answers(triviaqa_noisy_answers_6,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 6:')\n",
    "print(f\"{matches_triviaqa_6} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_6 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c549ee-95bd-47e2-b5db-bd06b1ef80e3",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d9fa2-8237-406d-9fe0-ee2c8a75668e",
   "metadata": {},
   "source": [
    "We apply re-ranking to both experiments. First to the SQuAD dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a46f0-fec5-43f6-a2c4-a03ad45d8f81",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f35fd6-a529-41bb-8558-2d2aa06af5da",
   "metadata": {},
   "source": [
    "First evaluate if the context is found between the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f61c047d-07a1-4308-abdb-db744ba480b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e888a2a1d93c46aaa13ad59875bab71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a34286c55e4a62bfde2c12869308a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset = dataset['validation']\n",
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )\n",
    "id_list = [doc.metadata['id'] for doc in docs_processed]\n",
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d61c122c-8f66-402e-a49b-c5ddae5d1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1fa6e476-0de3-4216-a537-8a291ec5615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_1.pkl', 'rb') as f:\n",
    "        VDB_l2_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "06f8bf25-031d-463d-ac60-a20701bad3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_1,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf717f01-7d5a-43fe-90b9-168e4f2a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    k_values = [1,2,3,4]\n",
    "    rerank_retrieve_results = []\n",
    "    # Iterate through the subset of questions\n",
    "    for row in tqdm(subset, desc=\"Evaluating questions\"):\n",
    "        question_id = row['id']\n",
    "        question_text = row['question']\n",
    "        actual_context = row['context']\n",
    "        # Evaluate for each k value\n",
    "        for k in k_values:\n",
    "            retrieved = rag_pipeline_with_rerank.retrieve_context(question_text,k=20)\n",
    "            retrieved_docs,scores = rag_pipeline_with_rerank.rerank_context(retrieved,k, question_text, return_scores = True)\n",
    "            found = any(doc == actual_context for doc in retrieved_docs)\n",
    "            rerank_retrieve_results.append({\n",
    "                \"question_id\": question_id,\n",
    "                \"question\": question_text,\n",
    "                \"actual_context\": actual_context,\n",
    "                \"k\": k,\n",
    "                \"retrieved_docs\": [doc for doc in retrieved_docs],\n",
    "                \"actual_context_found\": found,\n",
    "                \"scores\": scores,\n",
    "            })\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_retrieve_results.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_retrieve_results, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_retrieve_results.pkl', 'rb') as f:\n",
    "        rerank_retrieve_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7cd83eab-4ddb-4492-a11e-5e17a8150ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "df_results = pd.DataFrame(rerank_retrieve_results)\n",
    "\n",
    "# Group by `k` and calculate the number of times the actual context was found\n",
    "summary_table = df_results.groupby(\"k\").agg(\n",
    "    times_context_found=(\"actual_context_found\", \"sum\"),\n",
    "    total_questions=(\"actual_context_found\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "# Add a column for the percentage of times the context was found\n",
    "summary_table[\"percentage_found\"] = (\n",
    "    summary_table[\"times_context_found\"] / summary_table[\"total_questions\"] * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c806d3b0-cee7-48fa-9982-fafb35f051aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>times_context_found</th>\n",
       "      <th>total_questions</th>\n",
       "      <th>percentage_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1894</td>\n",
       "      <td>2067</td>\n",
       "      <td>91.630382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>2067</td>\n",
       "      <td>95.839381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>2067</td>\n",
       "      <td>97.194001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>2067</td>\n",
       "      <td>97.387518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  times_context_found  total_questions  percentage_found\n",
       "0  1                 1894             2067         91.630382\n",
       "1  2                 1981             2067         95.839381\n",
       "2  3                 2009             2067         97.194001\n",
       "3  4                 2013             2067         97.387518"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c6eda907-24bb-4de2-b79b-8427adb3968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1)\n",
    "        rerank_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers.pkl', 'rb') as f:\n",
    "        rerank_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b504ba89-93bf-4c7d-8ed9-6cf8b71e5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        rerank_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers_2.pkl', 'rb') as f:\n",
    "        rerank_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f4cb27fb-fafa-4513-a67b-8a6540d3339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        rerank_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers_3.pkl', 'rb') as f:\n",
    "        rerank_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "20263ee2-b228-4229-bcbe-a724426401ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c6521f0-0b51-451f-99f7-d8064e18b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b081c813b90742d2828814685d83e438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1 and rerank:\n",
      "1334 / 2067\n",
      "Exact Match Score: 0.6454\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank = evaluate_answers(rerank_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1 and rerank:')\n",
    "print(f\"{exact_matches_rerank} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2f14f451-8b02-4c48-97eb-1b6eea416289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc9b0b4cc5f4d1c81833d20b81b046b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2 and rerank:\n",
      "1279 / 2067\n",
      "Exact Match Score: 0.6188\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_2 = evaluate_answers(rerank_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2 and rerank:')\n",
    "print(f\"{exact_matches_rerank_2} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_2 / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6adcd881-a6df-43da-8c2c-39b46c00e342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec7ec18062846b2b78c2f1f7803eba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3 and rerank:\n",
      "1259 / 2067\n",
      "Exact Match Score: 0.6091\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_3 = evaluate_answers(rerank_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3 and rerank:')\n",
    "print(f\"{exact_matches_rerank_3} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_3 / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa14bc-928c-4a55-b17e-6f56342e1901",
   "metadata": {},
   "source": [
    "## With TriviaQA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5d051-6e1d-44f9-9e2c-d919fd92f10c",
   "metadata": {},
   "source": [
    "### With contexts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5eef28c4-d9eb-4ab0-9c87-3faef10ac783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfffd0418a3943a3965d2afe0cf2dd15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream the validation split of TriviaQA (rc.wikipedia.nocontext configuration)\n",
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\", streaming=True)\n",
    "\n",
    "# Collect the first 1000 entries\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "\n",
    "# Convert the list to a Hugging Face Dataset\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30b241c5-d885-4178-9207-897fc946ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7198db4c0f6e49289e59787e35d9fa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entity pages:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LangchainDocument objects created (after deduplication): 1537\n"
     ]
    }
   ],
   "source": [
    "Raw_contexts = []\n",
    "\n",
    "unique_contents = set()\n",
    "\n",
    "for entry in tqdm(subset, desc=\"Processing entity pages\"):\n",
    "        entity_pages = entry[\"entity_pages\"]\n",
    "        for i, context in enumerate(entity_pages[\"wiki_context\"]):\n",
    "            if context not in unique_contents:\n",
    "                unique_contents.add(context)\n",
    "                Raw_contexts.append(\n",
    "                    LangchainDocument(\n",
    "                        page_content=context,\n",
    "                        metadata={\n",
    "                            \"title\": entity_pages[\"title\"][i],\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Total LangchainDocument objects created (after deduplication): {len(Raw_contexts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "45515659-26c8-4d9e-8670-cfdfc9cfa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4376799a-bd20-4e06-9cad-266beb076069",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Raw_contexts,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "        docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6966786b-b8ec-48e1-8739-aed010f0e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 20000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ccf0867-f67d-4081-a5d7-1e9c874bf05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (111999, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fac81aef-be45-4fc3-8d6c-6ad93bb719af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    index.add(embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_contexts = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_contexts.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_contexts, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_contexts.pkl\", \"rb\") as f:\n",
    "        VDB_l2_contexts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d6c6f7ed-6732-469d-8d48-3ce0e108172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_contexts,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "90589c9a-3abc-4b05-b58a-5761b0dde490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1,return_context = True)\n",
    "        triviaqa_rerank_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50b28b45-fb07-41fb-ba39-8cf8f30bb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        triviaqa_rerank_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "120a1154-8b4c-4e43-9127-add6cf83029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        triviaqa_rerank_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "271793b6-417c-4b6a-8b55-ddf9a306cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ca0a05a-83e9-46d3-9b8b-d8c011ebb1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7452fe868d8c458ba1ebe47336cdc95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "547 / 1000\n",
      "Exact Match Score: 0.5470\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank = evaluate_answers(triviaqa_rerank_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_rerank} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a9e9f18-2cd5-401e-9013-c348ed6087e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ac599e78c648fc939584f5737d5cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "554 / 1000\n",
      "Exact Match Score: 0.5540\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_2 = evaluate_answers(triviaqa_rerank_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_rerank_2} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c61af53c-9cc1-4481-a7da-6175088cfd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec8403e9edd4a97af6b79d05a34365c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "554 / 1000\n",
      "Exact Match Score: 0.5540\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_3 = evaluate_answers(triviaqa_rerank_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_rerank_3} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97911d71-7bc0-41a0-8b7e-73ae0afa9193",
   "metadata": {},
   "source": [
    "### With Additional contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2e78fc65-93ec-4a43-a96f-3bb8cbbc8ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a977cf2a-67b1-4146-a0e9-b873f0543772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b32f8c0f0ebf4218a8ecbcc1b964267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Additional_documents = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "18cf956c-3eb6-4e55-9cf5-885d47838deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7050927-f78e-4a7b-b0c2-010a10de53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed_2 = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Additional_documents,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed_2, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed_2.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed_2, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed_2.pkl\", \"rb\") as f:\n",
    "        docs_processed_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eb4e9406-8304-492a-8bc6-7d56da4fcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings_2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 100000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3c153ea8-f662-4a3a-aa50-d5efe5bbb9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings_2\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings_2 = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings_2.shape}\")\n",
    "embeddings_2 = embeddings_2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "76529726-95e2-4a5c-9d9b-90994c268d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    all_embeddings = np.concatenate([embeddings, embeddings_2]).astype(np.float32)\n",
    "    index.add(all_embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    all_docs = docs_processed + docs_processed_2\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(all_docs)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_noisy = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_noisy.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_noisy, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_noisy.pkl\", \"rb\") as f:\n",
    "        VDB_l2_noisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df56fd52-29f4-4a0b-9ed2-5eac9f503256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_noisy,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8d48555f-5933-42ed-a8f0-5ce876c56715",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85493e4f-a0af-4f0f-b827-3dd017d90c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "585f0767-2c20-4a50-b840-f13e5346f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5bba61c9-ac25-45ee-810b-98eca4615df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd671bbe-e4af-4e38-9b25-dc4b3fc902f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ff7e09457a4574ba01091bae810166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "553 / 1000\n",
      "Exact Match Score: 0.5530\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy = evaluate_answers(triviaqa_rerank_noisy_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_rerank_noisy} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_noisy / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8eee6a69-04d0-4c3f-85ca-46a8c1d3c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb75dd4bedf34d21b8362695030b4c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "563 / 1000\n",
      "Exact Match Score: 0.5630\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy_2 = evaluate_answers(triviaqa_rerank_noisy_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_rerank_noisy_2} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_noisy_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ad4e9030-f3dd-4551-82f4-fe549b87044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7d5c6cb2cd4654b0d2f487fb61d291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "558 / 1000\n",
      "Exact Match Score: 0.5580\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy_3 = evaluate_answers(triviaqa_rerank_noisy_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_rerank_noisy_3} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_noisy_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbcc181-96dd-4029-a4e4-20b117d6b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d780eb-2f00-4b3a-829d-f6c2d9d10884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 205328/205328 [00:08<00:00, 23212.30it/s]\n"
     ]
    }
   ],
   "source": [
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"url\": doc[\"url\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faecfda2-52a3-4829-8b13-b58fc3698ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c100a06-fe1e-43f9-a533-19069c8c76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n\\n\",  # Paragraph breaks\n",
    "    \"\\n\",    # Line breaks\n",
    "    \". \",    # Sentence endings\n",
    "    \"? \",    # Question endings\n",
    "    \"! \",    # Exclamation endings\n",
    "    \" \",     # Fallback to spaces\n",
    "    \"\"       # Catch-all\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75656ca0-c1a4-440e-bf79-c319853e518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45e3c1cf-bc06-4a20-b578-fa3237af6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save docs_processed to a file\n",
    "with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs_processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69907955-121b-4e41-8bb6-74be7cf7ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs_processed from a file\n",
    "with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "    docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7a5ce-97f7-4ba1-bd97-991c44983160",
   "metadata": {},
   "source": [
    "Create the answers (Used colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c22941-bd79-4ba7-9cdd-506c6c72a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = \"embeddings\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 100000\n",
    "\n",
    "# Get already processed batches (for resuming)\n",
    "processed_batches = {\n",
    "    int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "}\n",
    "\n",
    "# Process documents in batches\n",
    "num_docs = len(docs_processed)\n",
    "for start_idx in range(0, num_docs, batch_size):\n",
    "    batch_number = start_idx // batch_size\n",
    "    if batch_number in processed_batches:\n",
    "        continue  # Skip already processed batches\n",
    "    \n",
    "    # Define end index for the current batch\n",
    "    end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "    batch_docs = docs_processed[start_idx:end_idx]\n",
    "    \n",
    "    try:\n",
    "        # Initialize embeddings for the batch\n",
    "        batch_embeddings = []\n",
    "        \n",
    "        # Compute embeddings with progress tracking within the batch\n",
    "        for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "            batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "        \n",
    "        # Convert batch embeddings to numpy array\n",
    "        batch_embeddings = np.array(batch_embeddings)\n",
    "        \n",
    "        # Save the batch to a file\n",
    "        batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "        np.save(batch_file, batch_embeddings)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_number}: {e}\")\n",
    "        # Save progress in case of an error\n",
    "        with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "            log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e112056-ca32-4480-b938-76482d49732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce71c3cc-2f50-4190-9908-190b3e0a9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding dimension and FAISS index\n",
    "embedding_dim = 384  \n",
    "index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "# Add precomputed embeddings to the FAISS index\n",
    "index.add(embeddings)\n",
    "# Convert metadata to Document objects\n",
    "metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "# Create the docstore\n",
    "docstore = InMemoryDocstore(metadata)\n",
    "# Create a mapping from FAISS IDs to docstore IDs\n",
    "index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "\n",
    "# Initialize the FAISS vector store\n",
    "VDB_l2 = FAISS(\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    "    embedding_function=embedding_function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6af86-6d26-4fd5-8d3c-4d2924b4b93d",
   "metadata": {},
   "source": [
    "We have the vector database, now get the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c4dbcd0-5348-4de8-a447-06915abf0b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10570/10570 [00:01<00:00, 6489.06it/s]\n",
      "Processing documents: 100%|██████████████████████████████████████████████████| 10570/10570 [00:00<00:00, 316676.74it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset = dataset['validation']\n",
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )\n",
    "id_list = [doc.metadata['id'] for doc in docs_processed]\n",
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77a877a-b1d6-4b27-b9e2-80c80e1c7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2,\n",
    "        retriever_kgt1=VDB_l2,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb1a63-383c-4ad0-baa9-a23b3fb1fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_answers = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "    wikipedia_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/wikipedia_answers.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79080eb0-cc8d-4f64-aa9b-5a611db137bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_answers_2 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer = rag_pipeline.generate_answer(question,k=2)\n",
    "    wikipedia_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/wikipedia_answers_2.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia_answers_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c39e0e-eb0f-4b9d-981c-8834ebe2780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_answers_3 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "    wikipedia_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/wikipedia_answers_3.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia_answers_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41940fe5-0df1-42c1-ab57-469f746a22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/wikipedia_answers.pkl', 'rb') as f:\n",
    "    wikipedia_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a2be9da-fc2f-4959-a9b0-95333f059295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 2067/2067 [00:00<00:00, 3116.70question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "111 / 2067\n",
      "Exact Match Score: 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_wiki = evaluate_answers(wikipedia_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_wiki} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_wiki / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eea4247a-4deb-45f8-b969-115cab6ece55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the Pickle file\n",
    "with open('PKL files/wikipedia_answers_2.pkl', 'rb') as f:\n",
    "    wikipedia_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc0eb1f7-2536-466e-87a8-1c8729941ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 2067/2067 [00:00<00:00, 2989.89question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "123 / 2067\n",
      "Exact Match Score: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Exact Matches with Tokenization\n",
    "exact_matches_wiki_2 = evaluate_answers(wikipedia_answers_2,tokenizer)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_wiki_2} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_wiki_2 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ab35c02-2b6d-4830-8f4b-df4c5972a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the Pickle file\n",
    "with open('PKL files/wikipedia_answers_3.pkl', 'rb') as f:\n",
    "    wikipedia_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26819d1a-e742-4a2a-be81-43b5b044cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 2067/2067 [00:00<00:00, 3279.98question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "136 / 2067\n",
      "Exact Match Score: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_wiki_3 = evaluate_answers(wikipedia_answers_3,tokenizer)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_wiki_3} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_wiki_3 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2eeec-2467-4505-9369-9f2e19e2f9ff",
   "metadata": {},
   "source": [
    "New questions dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cddbd1a-c545-4e4c-9d78-43b7ebead989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689b4b64be8440009e5a6f7cc5c3e0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream the validation split of TriviaQA (rc.wikipedia.nocontext configuration)\n",
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia.nocontext\", split=\"validation\", streaming=True)\n",
    "\n",
    "# Collect the first 1000 entries\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "\n",
    "# Convert the list to a Hugging Face Dataset\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset = subset.remove_columns(['question_source', 'entity_pages', 'search_results'])\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7266e5bf-3f31-46d6-a13a-855fdd14c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunset Blvd',\n",
       " 'West Sunset Boulevard',\n",
       " 'Sunset Boulevard',\n",
       " 'Sunset Bulevard',\n",
       " 'Sunset Blvd.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0]['answer']['aliases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d0618b-e108-4a22-884b-4e2954280556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|████████████████████████████████████████████████████| 1000/1000 [09:37<00:00,  1.73question/s]\n"
     ]
    }
   ],
   "source": [
    "triviaqa_answers = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "    triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/triviaqa_answers.pkl', 'wb') as f:\n",
    "    pickle.dump(triviaqa_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa18bb0-9094-4c9c-a071-cd2bb2eeacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/triviaqa_answers.pkl', 'rb') as f:\n",
    "    triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d8f6ac-feb3-4bfb-b20b-eef16a3d0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|████████████████████████████████████████████████████| 1000/1000 [10:34<00:00,  1.58question/s]\n"
     ]
    }
   ],
   "source": [
    "triviaqa_answers_2 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "    triviaqa_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/triviaqa_answers_2.pkl', 'wb') as f:\n",
    "    pickle.dump(triviaqa_answers_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3e28eeb-db96-4ef5-9388-b4284bd08a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/triviaqa_answers_2.pkl', 'rb') as f:\n",
    "    triviaqa_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12d7807-41db-4593-aa6b-a98c81c4a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|████████████████████████████████████████████████████| 1000/1000 [16:14<00:00,  1.03question/s]\n"
     ]
    }
   ],
   "source": [
    "triviaqa_answers_3 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "    triviaqa_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/triviaqa_answers_3.pkl', 'wb') as f:\n",
    "    pickle.dump(triviaqa_answers_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd291e8d-af70-45f8-8e9f-a82fd7abcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/triviaqa_answers_3.pkl', 'rb') as f:\n",
    "    triviaqa_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894a9ae7-a59c-4abe-9db6-4c4a95fdce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|███████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 444.36question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "289 / 1000\n",
      "Exact Match Score: 0.2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_triviaqa_1 = evaluate_answers(triviaqa_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_triviaqa_1} / {len(triviaqa_answers)}\")\n",
    "print(f\"Exact Match Score: {exact_matches_triviaqa_1 / len(triviaqa_answers):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4dba622-542a-4ce6-bc72-ac912d4827ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1262.30question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "309 / 1000\n",
      "Exact Match Score: 0.3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_triviaqa_2,errors = evaluate_answers(triviaqa_answers_2,tokenizer,return_errors = True)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_triviaqa_2} / {len(triviaqa_answers_2)}\")\n",
    "print(f\"Exact Match Score: {exact_matches_triviaqa_2 / len(triviaqa_answers_2):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525e3825-dbc1-49e6-a457-b4b02a57ceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|███████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 465.00question/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "302 / 1000\n",
      "Exact Match Score: 0.3020\n"
     ]
    }
   ],
   "source": [
    "exact_matches_triviaqa_3 = evaluate_answers(triviaqa_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_triviaqa_3} / {len(triviaqa_answers_3)}\")\n",
    "print(f\"Exact Match Score: {exact_matches_triviaqa_3 / len(triviaqa_answers_3):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b16d4f5a-06f0-4d04-b4ed-f9cae8c5fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'tc_538',\n",
       " 'question': 'In the 80s who wrote the novel Empire of The Sun?',\n",
       " 'answer': 'Ballard',\n",
       " 'ground_truths': ['JG Ballard',\n",
       "  'J.G. Ballard',\n",
       "  'James Graham Ballard',\n",
       "  'J. G. Ballard',\n",
       "  'J.G.Ballard',\n",
       "  'Jg ballard',\n",
       "  \"A User's Guide to the Millenium\",\n",
       "  'J G Ballard',\n",
       "  'Ballardian',\n",
       "  'James G. Ballard'],\n",
       " 'context': 'The 1980s and later\\n\\nJames Graham Ballard (often \"Jim\"; 15 November 1930 – 19 April 2009) was an English novelist, short story writer, and important member of the New Wave movement in science fiction. His best-known books are  Crash (1973) and Empire of the Sun (1984).\\n\\nLife'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triviaqa_answers_2[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c396ade2-5aa4-4d5a-b40f-989d96764d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "Model answer:  mr. wilson\n",
      "Ground truth:  Sunset Blvd\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Musicals\n",
      "\n",
      "Release dates \n",
      "\n",
      "1993 comedy movies\n",
      "1990s musical movies\n",
      "American musical comedy movies\n",
      "---------------------------------------------------------------------------\n",
      "Who was the next British Prime Minister after Arthur Balfour?\n",
      "Model answer:  Balfour\n",
      "Ground truth:  Sir Henry Campbell-Bannerman\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Arthur James Balfour, 1st Earl of Balfour, KG OM PC (25 July 1848 – 19 March 1930) was a British Conservative statesman and Prime Minister of the United Kingdom from 1902 until 1905.\n",
      "\n",
      "He was minister of Foreign Affairs from 1916 to 1919. In this capacity he wrote the so-called Balfour Declaration in 1917.\n",
      "\n",
      "1848 births\n",
      "1930 deaths\n",
      "Former Conservative Party (UK) MPs\n",
      "Government ministers\n",
      "Knights of the Garter\n",
      "Order of Merit\n",
      "Members of the Privy Council of the United Kingdom\n",
      "United Kingdom Earls\n",
      "Zionists\n",
      "\n",
      "List of prime ministers \n",
      "\n",
      "Politics of the United Kingdom\n",
      "---------------------------------------------------------------------------\n",
      "Who had a 70s No 1 hit with Kiss You All Over?\n",
      "Model answer:  Dr. Love Ladies Room\n",
      "Ground truth:  Internal exile\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Rock and Roll Over is the fifth studio album and sixth album overall by the American hard rock/heavy metal band Kiss. It was released on November 11, 1976.\n",
      "\n",
      "Track listing \n",
      "I Want You\n",
      "Take Me\n",
      "Calling Dr. Love\n",
      "Ladies Room\n",
      "Baby Driver\n",
      "Love 'Em and Leave 'Em\n",
      "Mr. Speed\n",
      "See You in Your Dreams\n",
      "Hard Luck Woman\n",
      "Makin' Love\n",
      "\n",
      "Kiss albums\n",
      "1976 albums\n",
      "Hard rock albums\n",
      "Heavy metal albums\n",
      "\n",
      "Kiss career\n",
      "---------------------------------------------------------------------------\n",
      "Which actress was voted Miss Greenwich Village in 1942?\n",
      "Model answer:  sarah wilson\n",
      "Ground truth:  Bacall\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "1942 births\n",
      "Living people\n",
      "American fashion designers\n",
      "Businesspeople from New York City\n",
      "\n",
      "1942 births\n",
      "Living people\n",
      "American judges\n",
      "Lawyers from New York City\n",
      "Jewish American entertainers\n",
      "Jewish American writers\n",
      "Jewish judges\n",
      "Jewish lawyers\n",
      "Television personalities from New York City\n",
      "Writers from Brooklyn\n",
      "Women judges\n",
      "---------------------------------------------------------------------------\n",
      "What was the name of Michael Jackson's autobiography written in 1988?\n",
      "Model answer:  Michael Jackson\n",
      "Ground truth:  Walk on the Moon\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "References\n",
      "\n",
      "1988 movies\n",
      "Michael Jackson\n",
      "American superhero movies\n",
      "\n",
      "Michael Jackson\n",
      "---------------------------------------------------------------------------\n",
      "Which volcano in Tanzania is the highest mountain in Africa?\n",
      "Model answer:  Mount Kenya\n",
      "Ground truth:  Mawensi\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Mount Kenya is the highest mountain in Kenya. It is  high. It is the second highest mountain in Africa. It is an extinct volcano. It is on the equator. It is  northeast of Nairobi.\n",
      "\n",
      "References\n",
      "\n",
      "Geography of Kenya\n",
      "Mountains of Africa\n",
      "\n",
      "Tanzania\n",
      "---------------------------------------------------------------------------\n",
      "The flag of Libya is a plain rectangle of which color?\n",
      "Model answer:  red\n",
      "Ground truth:  Greenishly\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The Flag of Libya has three horizontal stripes of red, black, and green, with a white crescent and star in the center of the black stripe.  It has been the official flag of Libya since 3 August 2011.\n",
      "\n",
      "Overview \n",
      "The flag is the same as the flag of the earlier Kingdom of Libya, used from 1951 to 1969.  During the dictatorship of Muammar al-Gaddafi the flag was changed twice and it was just a plain field of green. It was unique for being the only national flag in the world with just one color and no design, emblems, coat of arms, or any other details. It was adopted on 11 November 1977.\n",
      "\n",
      "Related pages\n",
      "Flag of Libya (1977–2011)\n",
      "\n",
      "References \n",
      "\n",
      "Libya\n",
      "Libya\n",
      "1951 establishments\n",
      "1969 disestablishments\n",
      "2011 establishments\n",
      "---------------------------------------------------------------------------\n",
      "Which musical featured the song The Street Where You Live?\n",
      "Model answer:  Musicals\n",
      "Ground truth:  My Fair Lady (2010 film)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Musicals\n",
      "\n",
      "The musical opened in 1980 in Paris. In 1985, it opened in London's West End. In 1987, it opened on Broadway. It won a Tony Award for Best Musical, and a Drama Desk Award for Outstanding Musical. In 2012, it was adapted to a movie starring Hugh Jackman, Russell Crowe, and Anne Hathaway.\n",
      "\n",
      "1980s musicals\n",
      "Broadway musicals\n",
      "Fiction set in the past\n",
      "Musicals adapted to movies\n",
      "Musicals based on books\n",
      "Tony Award winning musicals\n",
      "West End musicals\n",
      "---------------------------------------------------------------------------\n",
      "Who had an 80s No 1 hit with Hold On To The Nights?\n",
      "Model answer:  Ariola\n",
      "Ground truth:  Richard Noel Marx\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Singles\n",
      "\"Hide Away – Man Is Coming'!\" (1985, Ariola)\n",
      "\"Touch in the Night\" (1985, Ariola)\n",
      "\"Stop the Rain\" / \"Shy Girl\" (1986, ZYX Music)\n",
      "\"Love Is Just a Word\" (1986)\n",
      "\"Time for Love\" (1986)\n",
      "\"Danger Danger\" (1987)\n",
      "\"Oh, Don't Lose Your Heart Tonight\" (1987)\n",
      "\n",
      ". He also performed the songs \"I'm Alright\" (peaked at #7 in the U.S.), \"Mr. Night\" and \"Lead the Way\" from Caddyshack (1980), and \"Meet Me Half Way\" from Over the Top (1987).\n",
      "---------------------------------------------------------------------------\n",
      "Who directed the classic 30s western Stagecoach?\n",
      "Model answer:  United Artists\n",
      "Ground truth:  John Ford (1895-1973)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Stagecoach is a 1939 American western movie directed by John Ford and was based on the 1937 short story The Stage to Lordsburg by Ernest Haycox. It stars John Wayne, Claire Trevor, Andy Devine, John Carradine, Thomas Mitchell, Louise Platt, George Bancroft and was distributed by United Artists. It was nominated for 7 Academy Awards and won 2 in 1940 and was remade as Stagecoach in 1966 and 1986.\n",
      "\n",
      "Other websites\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "1939 movies\n",
      "1930s western movies\n",
      "American western movies\n",
      "Movies based on short stories\n",
      "Movies directed by John Ford\n",
      "\n",
      "Stagecoach to Fury is a 1956 American western movie directed by William F. Claxton and starring Forrest Tucker, Mari Blanchard, Wallace Ford, Paul Fix, Wright King, Ellen Corby, Rayford Barnes. It was distributed by 20th Century Fox.\n",
      "\n",
      "Other websites\n",
      "\n",
      "1956 movies\n",
      "1950s western movies\n",
      "American western movies\n",
      "Movies directed by William F. Claxton\n",
      "---------------------------------------------------------------------------\n",
      "Which highway was Revisited in a classic 60s album by Bob Dylan?\n",
      "Model answer:  The Danger Zone\n",
      "Ground truth:  61\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "In this context, \"hit the road\" is an idiom meaning \"get lost,\" as the following words indicate.\n",
      "\n",
      "Recording Details\n",
      "For the most popular recording\n",
      " Title: \"Hit the Road Jack\"\n",
      " Artist: Single by Ray Charles\n",
      " B-side: \"The Danger Zone\"\n",
      " Released: September 1961\n",
      " Format: 7\", 45rpm\n",
      " Genre: R&B\n",
      " Length: 2:00\n",
      " Label: ABC\n",
      " Writer(s): Percy Mayfield\n",
      "\n",
      "1961 songs\n",
      "R&B songs\n",
      "\n",
      "Studio albums\n",
      "\n",
      "Live albums\n",
      "\n",
      "Soundtracks\n",
      "\n",
      "Compilations\n",
      "\n",
      "Collaborations with Bob Dylan\n",
      "\n",
      "Singles\n",
      "\n",
      "References\n",
      "---------------------------------------------------------------------------\n",
      "Which was the only eastern bloc country to participate in the 1984 LA Olympics?\n",
      "Model answer:  Yugoslavia\n",
      "Ground truth:  ISO 3166-1:RO\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The 1984 Olympics could mean:\n",
      "The 1984 Summer Olympics in Los Angeles, United States\n",
      "The 1984 Winter Olympics in Sarajevo, Yugoslavia\n",
      "\n",
      "The 1984 Summer Olympics, officially known as the Games of the XXIII Olympiad, were held in Los Angeles, United States from July 28 to August 12.\n",
      "\n",
      "1984 Summer Olympics\n",
      "---------------------------------------------------------------------------\n",
      "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?\n",
      "Model answer:  Marvel Comics\n",
      "Ground truth:  Wild Palms\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Fictional universes\n",
      "Marvel Comics\n",
      "\n",
      "Comic book\n",
      "---------------------------------------------------------------------------\n",
      "If I Were A Rich Man Was a big hit from which stage show?\n",
      "Model answer:  saturday night\n",
      "Ground truth:  Fiddler on a Roof\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Famous concerts\n",
      "\n",
      "Musicals\n",
      "Elton John\n",
      "---------------------------------------------------------------------------\n",
      "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?\n",
      "Model answer:  Men Against the Sea\n",
      "Ground truth:  HMS Bounty mutineers\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Pitcairn Island\n",
      "\n",
      "Shipwreck Island is the second book of the trilogy written by Struan Murray and first published on March 4, 2021.\n",
      "\n",
      "References \n",
      "\n",
      "2021 books\n",
      "Children's books\n",
      "Fantasy books\n",
      "---------------------------------------------------------------------------\n",
      "What was Truman Capote's last name before he was adopted by his stepfather?\n",
      "Model answer:  Corozzo\n",
      "Ground truth:  Perſons\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Truman Capote (born Truman Streckfus Persons, September 30, 1924 - August 25, 1984) was an American author. He was born in New Orleans, Louisiana and grew up in Monroeville, Alabama, New York City and Greenwich, Connecticut. He is best known for writing the half-true novel, In Cold Blood. The novel is based on a murder that happened in Kansas in the 1950s. He became good friends with the man accused of the murder.\n",
      "\n",
      "Capote was openly gay. He died of liver cancer in Los Angeles, California, aged 59.\n",
      "\n",
      "References\n",
      "\n",
      "Current family Capos \n",
      " Nicholas \"Little Nick\" Corozzo - Capo and Boss of the Gambino crime family. Brother of Consigliere Joseph Corozzo, uncle of Joseph Jr. and the current head of the caporegimes. Became a fugitive for almost four months, currently incarcerated.\n",
      "---------------------------------------------------------------------------\n",
      "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?\n",
      "Model answer:  Sylvie and Bruno\n",
      "Ground truth:  Boojum (disambiguation)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The Hunting of the Snark (An Agony in 8 Fits) is a nonsense poem written by Lewis Carroll, the pen name of Charles Lutwidge Dodgson.\n",
      "\n",
      "The Hunting of the Snark (1876)\n",
      " Rhyme? and Reason? (1883) A collection of poems, including Phantasmagoria and The Hunting of the Snark\n",
      " A Tangled Tale (1886)\n",
      " Sylvie and Bruno (1889)\n",
      " Sylvie and Bruno Concluded (1893)\n",
      " Three Sunsets and other poems\n",
      " What the Tortoise said to Achilles (1895)\n",
      "---------------------------------------------------------------------------\n",
      "Art Garfunkel trained for which profession although he didn't qualify?\n",
      "Model answer:  singer\n",
      "Ground truth:  Master Builder (occupation)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Art Garfunkel (born November 5, 1941) is an American singer of Jewish descent. Along with Paul Simon, he was part of the duo Simon and Garfunkel, a popular group in the 1960s and early 1970s. After that, he made several solo albums. He has also acted in a few movies.\n",
      "\n",
      "Career before becoming a professional\n",
      "---------------------------------------------------------------------------\n",
      "In the 80s who wrote the novel Empire of The Sun?\n",
      "Model answer:  Ballard\n",
      "Ground truth:  JG Ballard\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The 1980s and later\n",
      "\n",
      "James Graham Ballard (often \"Jim\"; 15 November 1930 – 19 April 2009) was an English novelist, short story writer, and important member of the New Wave movement in science fiction. His best-known books are  Crash (1973) and Empire of the Sun (1984).\n",
      "\n",
      "Life\n",
      "---------------------------------------------------------------------------\n",
      "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?\n",
      "Model answer:  Bette Davis Eyes\n",
      "Ground truth:  Stars on 45 (Single)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Kim Carnes (born 20 July 1945) is an American singer. She is best known for the song \"Bette Davis Eyes\" (1981).\n",
      "Bette Davis liked the song.  Carnes gave Davis a gold record.  Bette Davis hung the gold record on a wall.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      " Kim Carnes - Official Web Site\n",
      " Kim Carnes Fan Club Web Site\n",
      " \n",
      "\n",
      "American folk musicians\n",
      "Singers from Los Angeles\n",
      "American pop musicians\n",
      "Singer-songwriters from California\n",
      "Grammy Award winners\n",
      "1945 births\n",
      "Living people\n",
      "Country musicians\n",
      "\n",
      "In 1981 Kim Carnes sang the hit song \"Bette Davis Eyes\". Davis liked the song. Carnes gave Davis a gold record. Davis hung the gold record on a wall.\n",
      "\n",
      "The Kennedy Center honored Davis in 1987. She died of breast cancer in Neuilly-sur-Seine, France.\n",
      "\n",
      "Other websites \n",
      " Bette Davis at Classic Actresses \n",
      " Classic Movies (1939 - 1969): Bette Davis\n",
      "\n",
      "Sources\n",
      "---------------------------------------------------------------------------\n",
      "What was Walter Matthau's first movie?\n",
      "Model answer:  The Odd Couple II\n",
      "Ground truth:  The Kentuckian\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Walter Matthau (October 1, 1920–July 1, 2000) was an American actor. He starred with Jack Lemmon in The Odd Couple and its sequel The Odd Couple II. He won the Academy Award for The Fortune Cookie.\n",
      "\n",
      "First movies\n",
      "---------------------------------------------------------------------------\n",
      "Which musician founded the Red Hot Peppers?\n",
      "Model answer:  Anthony Kiedis\n",
      "Ground truth:  Ferdinand Joseph La Menthe\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Band history\n",
      "\n",
      "Creation \n",
      "Red Hot Chili Peppers were originally called Tony Flow and the Miraculously Majestic Masters of Mayhem. The band was started in 1983 for a single performance. They were so popular that they were asked to come back again the next week. The first members of the band were Anthony Kiedis (singer), Flea (bass), Hillel Slovak (guitar), and Jack Irons (drums). They all knew each other from Fairfax High School in Los Angeles.\n",
      "\n",
      "For the pepper, see Chilli pepper.\n",
      "Red Hot Chili Peppers are an American rock band. The band started in 1983 in Los Angeles, California. The state of California has been a theme in many of their songs. The members of the band are singer Anthony Kiedis, bass guitarist Flea, guitarist John Frusciante, and drummer Chad Smith.\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in errors:\n",
    "    print(triviaqa_answers_2[index]['question'])\n",
    "    print('Model answer: ',triviaqa_answers_2[index]['answer'])\n",
    "    print('Ground truth: ',triviaqa_answers_2[index]['ground_truths'][0])\n",
    "    print('--------------------------------------\\n','Retrieved context:')\n",
    "    print(triviaqa_answers_2[index]['context'])\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    if index>30:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
