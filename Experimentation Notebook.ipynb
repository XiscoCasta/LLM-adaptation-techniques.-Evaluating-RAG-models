{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee85def-595b-47bc-a2fb-aea034ad124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datasets import Dataset,load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.schema import Document\n",
    "from functions import CustomHuggingFaceEmbeddings, GenerativePipeline, tokenize_compare, RAGPipeline, split_documents, evaluate_vector_databases, evaluate_answers, RAGPipeline_with_rerank\n",
    "import faiss\n",
    "def embedding_function(text):\n",
    "    return embedding_model_1.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88bb4977-d3cc-4d97-af2f-ef7182681a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag to choose between generating all answers and databases or load them from the disk\n",
    "Generating = True\n",
    "#In case of generating them, flag to choose between saving them on the disk or not.\n",
    "Saving = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2c68a34-ed06-41c5-87ee-5f185aa355fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"PKL files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44119407-c989-49cd-bf54-f24f39279982",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# First experiment. Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17904c2-db3b-40f4-8b0c-27f432b09b2c",
   "metadata": {},
   "source": [
    "We will use the SQuAD dataset, which contains paired question-context data. We will use its validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af2b502a-4a96-49bc-802f-665ae59598c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a19b08-f200-4e20-b46e-21315ace981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76c72c-241b-4e9a-be56-b77e58b3ca8a",
   "metadata": {},
   "source": [
    "We will not split the documents, as they are already short context documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f484e1-e1cd-403b-b365-8d7da78fab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74f8911a-2ff6-4f77-b189-d22b135be012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10570/10570 [00:01<00:00, 8546.75it/s]\n"
     ]
    }
   ],
   "source": [
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70868961-b258-4ec8-a182-43ef30a16d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████████████████████████████████████████████| 10570/10570 [00:00<00:00, 283331.91it/s]\n"
     ]
    }
   ],
   "source": [
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb784be7-da7c-4c25-a171-f8f2a316b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2067"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a2a99-5b61-4053-8883-3275949c7a56",
   "metadata": {},
   "source": [
    "As there is only 2067 unique contexts, I will extract a question randomly for each context, and examine which vector database gets better result with the different similarity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "118b71e0-c06b-4ca9-885d-2fbf07c196e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [doc.metadata['id'] for doc in docs_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd108176-dce6-464a-9034-4e683ea67e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465f647-ee12-4335-9960-c19f03df492f",
   "metadata": {},
   "source": [
    "Once converted to LangChain documents, just embed them into a vector database with different similarity metrics. The first model used will be NoInstruct small Embedding v0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91d9fb09-743f-493a-8440-2ce1e93a9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3ceb249-7301-4dec-b20d-a4c8e3c93565",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_1.pkl', 'rb') as f:\n",
    "        VDB_l2_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7397b057-a20d-40c5-8e1c-7684e3bd2902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_1.pkl', 'rb') as f:\n",
    "        VDB_dot_product_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c6e6dd5-9bec-47ab-b6dd-c6f23fde7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_1.pkl', 'rb') as f:\n",
    "        VDB_cosine_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0744c6c0-fc52-41b9-8d8c-4398a70c7f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [22:26<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_1       0.721335  0.830189  0.876149  0.923077  0.959361  0.981616\n",
       "VDB_dot_product_1  0.721335  0.830189  0.876149  0.923077  0.959361  0.981616\n",
       "VDB_l2_1           0.721335  0.830189  0.876149  0.923077  0.959361  0.981616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Define the databases and their names\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_1\": VDB_cosine_1,\n",
    "    \"VDB_l2_1\": VDB_l2_1,\n",
    "    \"VDB_dot_product_1\": VDB_dot_product_1,\n",
    "}\n",
    "# Define the k values\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table1 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  # Calculate mean to get the proportion of `True` (True = 1, False = 0)\n",
    "    .unstack()  # Convert 'k' into columns\n",
    ")\n",
    "pivot_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cab203-59b6-42a8-8c0f-5925b41f2206",
   "metadata": {},
   "source": [
    "Repeat for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcf73204-744c-49cd-bc7a-5174249af282",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME2 = \"mavihsrr/bge-small-retail-finetuned\"\n",
    "embedding_model_2 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf9435a9-164f-41ab-be6d-88d1b1d72b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_2 = FAISS.from_documents(docs_processed, embedding_model_2,distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_2.pkl', 'rb') as f:\n",
    "        VDB_l2_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7befd66-cde5-4f6e-a55b-554fcf910217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_2 = FAISS.from_documents(docs_processed, embedding_model_2, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_2.pkl', 'rb') as f:\n",
    "        VDB_dot_product_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "428f3c3b-346d-4eb8-9101-c262e9203a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_2 = FAISS.from_documents(docs_processed, embedding_model_2, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_2.pkl', 'rb') as f:\n",
    "        VDB_cosine_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "959af461-558d-4b4b-953e-957bd0ae80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [20:47<00:00,  1.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_2       0.728592  0.828737  0.874214  0.920174  0.955007  0.981132\n",
       "VDB_dot_product_2  0.728592  0.828737  0.874214  0.920174  0.955007  0.981132\n",
       "VDB_l2_2           0.728592  0.828737  0.874214  0.920174  0.955007  0.981132"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the databases and their names\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_2\": VDB_cosine_2,\n",
    "    \"VDB_l2_2\": VDB_l2_2,\n",
    "    \"VDB_dot_product_2\": VDB_dot_product_2,\n",
    "}\n",
    "\n",
    "# Define the k values\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table2 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  \n",
    "    .unstack()\n",
    ")\n",
    "pivot_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb7f59d3-895e-48a9-9431-86ff3572279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-s and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME3 = \"Snowflake/snowflake-arctic-embed-s\"\n",
    "embedding_model_3 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8b090bf-3fd3-48ca-a080-f4204a97d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_3 = FAISS.from_documents(docs_processed, embedding_model_3,distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_3.pkl', 'rb') as f:\n",
    "        VDB_l2_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fdc8c36-e446-4f8e-90d8-d5262ef62955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_3 = FAISS.from_documents(docs_processed, embedding_model_3, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_3.pkl', 'rb') as f:\n",
    "        VDB_dot_product_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c1a159f-d58c-45e0-8348-0ff01dfc642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_3 = FAISS.from_documents(docs_processed, embedding_model_3, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_3.pkl', 'rb') as f:\n",
    "        VDB_cosine_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a1fd7ed-2b9e-4b1f-bd6d-b1685777321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [16:41<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_3       0.583938  0.707305  0.769231  0.823416  0.893566  0.936139\n",
       "VDB_dot_product_3  0.583938  0.707305  0.769231  0.823416  0.893566  0.936139\n",
       "VDB_l2_3           0.583938  0.707305  0.769231  0.823416  0.893566  0.936139"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the databases and their names\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_3\": VDB_cosine_3,\n",
    "    \"VDB_l2_3\": VDB_l2_3,\n",
    "    \"VDB_dot_product_3\": VDB_dot_product_3,\n",
    "}\n",
    "\n",
    "# Define the k values\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table3 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  # Calculate mean to get the proportion of `True` (True = 1, False = 0)\n",
    "    .unstack()  # Convert 'k' into columns\n",
    ")\n",
    "pivot_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b589d1-9bda-4565-bce7-dab66bf33078",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Second experiment. Baseline, contexted and RAG models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db4a39e5-a6d2-4d81-802a-5bce06bed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativePipeline()\n",
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3835a6ab-3076-4acb-9f8b-e64f79a7fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    baseline_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = model.generate_answer(question, context=\"\")  # Empty context\n",
    "        baseline_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths': subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/baseline_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(baseline_answers, f)\n",
    "else:\n",
    "    with open('PKL files/baseline_answers.pkl', 'rb') as f:\n",
    "        baseline_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86df60ee-bcbf-4847-813e-4e470aff0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    contexted_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        context = subset[i]['context']\n",
    "        answer = model.generate_answer(question,context)\n",
    "        contexted_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/contexted_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(contexted_answers, f)\n",
    "else:\n",
    "    with open('PKL files/contexted_answers.pkl', 'rb') as f:\n",
    "        contexted_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4794bbf9-8c65-4bef-8cf9-25ca6dd3bded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b4fe7cb11b41b2b1ede53d723290fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for baseline model:\n",
      "37 / 2067\n",
      "Exact Match Score: 0.0179\n"
     ]
    }
   ],
   "source": [
    "exact_matches,errors = evaluate_answers(baseline_answers,tokenizer,return_errors = True)\n",
    "# Print results\n",
    "print('Evaluation score for baseline model:')\n",
    "print(f\"{exact_matches} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b38d3191-b45f-4701-900d-aab475652dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f51295cb314a5db0318364d5cdaf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for model with correct context:\n",
      "1438 / 2067\n",
      "Exact Match Score: 0.6957\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Exact Matches with Tokenization\n",
    "exact_matches_2 = evaluate_answers(contexted_answers, tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for model with correct context:')\n",
    "print(f\"{exact_matches_2} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_2 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f635d0f-4952-4585-889d-0d99fd443e8c",
   "metadata": {},
   "source": [
    "Maximum expected. Let's see RAG. We use VDB_l2_1 and VDB_l2_2 depending on the k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec019bb0-a546-4b10-9ab2-fc22a384981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_2,\n",
    "        retriever_kgt1=VDB_l2_1,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70162077-c5d8-4bcf-a592-b901f5b8a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        rag_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers.pkl', 'rb') as f:\n",
    "        rag_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "545572d7-6d2e-4fbf-8504-9878322ccffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        rag_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers_2.pkl', 'rb') as f:\n",
    "        rag_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f760871-c141-468c-a2ad-1044dd80315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        rag_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers_3.pkl', 'rb') as f:\n",
    "        rag_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02b1693c-3ce8-4ecc-a812-8e6192c84fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e071948d0a824045a5c5cf679c7dadd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "1082 / 2067\n",
      "Exact Match Score: 0.5235\n"
     ]
    }
   ],
   "source": [
    "exact_matches_3 = evaluate_answers(rag_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_3} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_3 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdb6d570-9e14-4d06-87bb-dc5edae1ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b46b7cd3594132aa101d8235d97497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k=2:\n",
      "1165 / 2067\n",
      "Exact Match Score: 0.5636\n"
     ]
    }
   ],
   "source": [
    "exact_matches_4 = evaluate_answers(rag_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k=2:')\n",
    "print(f\"{exact_matches_4} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_4 / 2067:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "109ad974-0427-4964-ace7-e02aef59cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd3f48ec974424aa8ec013739fa6556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k=3:\n",
      "1163 / 2067\n",
      "Exact Match Score: 0.5627\n"
     ]
    }
   ],
   "source": [
    "exact_matches_5 = evaluate_answers(rag_answers_3,tokenizer)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k=3:')\n",
    "print(f\"{exact_matches_5} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_5 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb55340-a89c-499c-9ba1-f67ae0c8c91d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Natural questions from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "822b4696-ba49-4325-94ca-ae7a02701e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e082a9c1-39a4-452e-a594-fbc3d596c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74b19ead7ba4087a4b975bc2fd50863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream the validation split of TriviaQA (rc.wikipedia.nocontext configuration)\n",
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\", streaming=True)\n",
    "\n",
    "# Collect the first 1000 entries\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "\n",
    "# Convert the list to a Hugging Face Dataset\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bda410d3-aac4-4323-a4a0-e44bed36b8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which Lloyd Webber musical premiered in the US on 10th December 1993?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0]['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbae74-8cdd-4d15-b454-49b3d49a18b3",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2357b72-a9bd-466c-b8ef-0e9eb50201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativePipeline()\n",
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7077ccd-94a0-45ad-9c74-11b2651df084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3be00c51e97491c8f2240fe79a85abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if Generating:\n",
    "    baseline_triviaqa_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = model.generate_answer(question, context=\"\")  # Empty context\n",
    "        baseline_triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths': subset[i][\"answer\"]['aliases']})\n",
    "    if Saving:\n",
    "        with open('PKL files/baseline_triviaqa_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(baseline_triviaqa_answers, f)\n",
    "else:\n",
    "    with open('PKL files/baseline_triviaqa_answers.pkl', 'rb') as f:\n",
    "        baseline_triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acb54c97-19df-4d11-ac05-357985d598e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c388235f1a8540d584404c3cc20dfd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for baseline model:\n",
      "70 / 1000\n",
      "Exact Match Score: 0.0700\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_baseline = evaluate_answers(baseline_triviaqa_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for baseline model:')\n",
    "print(f\"{matches_triviaqa_baseline} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_baseline / 1000:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7739bb-c112-4a9b-b882-5ca2bcea969d",
   "metadata": {},
   "source": [
    "## Extracting actual Contexts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdaabb69-4787-4182-85f6-43838e30cbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a57d2fb8d8415d955c9b3c2d9115f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n"
     ]
    }
   ],
   "source": [
    "suma = 0\n",
    "for doc in tqdm(subset['entity_pages']):\n",
    "    suma += len(doc[\"wiki_context\"])\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb3d5dcb-ad1b-4ee2-9c80-35e5494ed395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6fd882cc774d8d98132b1b1f5f9365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entity pages:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LangchainDocument objects created (after deduplication): 1537\n"
     ]
    }
   ],
   "source": [
    "Raw_contexts = []\n",
    "\n",
    "unique_contents = set()\n",
    "\n",
    "for entry in tqdm(subset, desc=\"Processing entity pages\"):\n",
    "        entity_pages = entry[\"entity_pages\"]\n",
    "        for i, context in enumerate(entity_pages[\"wiki_context\"]):\n",
    "            if context not in unique_contents:\n",
    "                unique_contents.add(context)\n",
    "                Raw_contexts.append(\n",
    "                    LangchainDocument(\n",
    "                        page_content=context,\n",
    "                        metadata={\n",
    "                            \"title\": entity_pages[\"title\"][i],\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Total LangchainDocument objects created (after deduplication): {len(Raw_contexts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfabfa-622d-41ca-a8b5-4624a854b021",
   "metadata": {},
   "source": [
    "There is a total of 1717 contexts, and when deleting the duplicates there is 1537."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0e8db9c-5460-4a53-a926-fd3c2e1b9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0688d55-ea24-42ad-938e-694a57364bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Raw_contexts,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "        docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee368ade-43c4-48c3-8a94-87251508f743",
   "metadata": {},
   "source": [
    "Next cell is done by batches and requires saving always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8260e067-5de8-40a9-85b7-481b4a0a1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 20000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e03d0b0-b3d9-4dff-abb2-0b0d733a7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (111999, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55c1c6c6-8eba-425d-b60f-35065c42eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    index.add(embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_contexts = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_contexts.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_contexts, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_contexts.pkl\", \"rb\") as f:\n",
    "        VDB_l2_contexts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5a77f452-f299-4ade-ac85-68d1d6e690df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_contexts,\n",
    "        retriever_kgt1=VDB_l2_contexts,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dea5a8ef-bb1f-4850-80cc-e89ffd0b4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers.pkl', 'rb') as f:\n",
    "        triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4686b9b-5250-4475-830e-ed3ff5bc0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        triviaqa_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30a6a64f-ddd4-4e14-96f6-8fc990cb9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        triviaqa_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e766c10e-ab60-4bfa-a6b7-770af4a6a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_4 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=4,return_context = True)\n",
    "        triviaqa_answers_4.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_4.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_4, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_4.pkl', 'rb') as f:\n",
    "        triviaqa_answers_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3a5a8bd-59f8-4a9d-b2d3-83d5e3fd25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_5 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=5,return_context = True)\n",
    "        triviaqa_answers_5.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_5.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_5, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_5.pkl', 'rb') as f:\n",
    "        triviaqa_answers_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "560095f6-31d9-45f9-bcb9-05480bbff864",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_6 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=6,return_context = True)\n",
    "        triviaqa_answers_6.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_6.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_6, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_6.pkl', 'rb') as f:\n",
    "        triviaqa_answers_6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19822f55-fead-4426-b266-56b211f17018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d501fd91cef461a968d1ef4ef54499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "384 / 1000\n",
      "Exact Match Score: 0.3840\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa = evaluate_answers(triviaqa_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{matches_triviaqa} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7fcace7-eee5-41e8-ab12-8099fecf34ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141f10622ddb49758d7d8e72cc002f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "457 / 1000\n",
      "Exact Match Score: 0.4570\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_2 = evaluate_answers(triviaqa_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{matches_triviaqa_2} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7823bcff-f341-47d5-80cd-fa9ae88d8d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdd2ee5d94a4f3aafda16baeaa4ff2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "476 / 1000\n",
      "Exact Match Score: 0.4760\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_3 = evaluate_answers(triviaqa_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{matches_triviaqa_3} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df5d8dac-3db8-4322-b0af-e4305d5724d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c478deacf5f749c19ffcbbf2651a9e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 4:\n",
      "487 / 1000\n",
      "Exact Match Score: 0.4870\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_4 = evaluate_answers(triviaqa_answers_4,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 4:')\n",
    "print(f\"{matches_triviaqa_4} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_4 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2faffb1b-fc8d-4aac-b651-c29d98a08a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edb746c24db4cc28c659f55e97a5141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 5:\n",
      "478 / 1000\n",
      "Exact Match Score: 0.4780\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_5 = evaluate_answers(triviaqa_answers_5,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 5:')\n",
    "print(f\"{matches_triviaqa_5} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_5 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f82f936-11a2-45f5-8d35-76f7bee8b425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38d6b22901a49eb93f7024856612795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 6:\n",
      "475 / 1000\n",
      "Exact Match Score: 0.4750\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_6 = evaluate_answers(triviaqa_answers_6,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 6:')\n",
    "print(f\"{matches_triviaqa_6} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_6 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522cc4a-c104-4832-9d11-ae4a0620363d",
   "metadata": {},
   "source": [
    "## Additional wikipedia passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af15169-3d2c-468d-8f7e-31df992082d0",
   "metadata": {},
   "source": [
    "We add wikipedia passages to go to a more real case, where we have additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9c5aa64-6bb2-4e35-b8c8-6ee69b1d38a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bd48893-2d7f-4b17-87a2-ae23f4cdf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d448a784c384893b25c9f1b506dddf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Additional_documents = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6a69e00-e291-4f2a-b4d8-8d1dbd6742be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed_2 = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Additional_documents,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed_2, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed_2.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed_2, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed_2.pkl\", \"rb\") as f:\n",
    "        docs_processed_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2afe0d66-5ecf-4832-9d57-d691c39554cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings_2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 100000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41cb9690-ccbd-46e4-b247-339598d45631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings_2\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings_2 = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings_2.shape}\")\n",
    "embeddings_2 = embeddings_2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bc7b485-1307-42fe-947e-e567b6ad78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    all_embeddings = np.concatenate([embeddings, embeddings_2]).astype(np.float32)\n",
    "    index.add(all_embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    all_docs = docs_processed + docs_processed_2\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(all_docs)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_noisy = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_noisy.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_noisy, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_noisy.pkl\", \"rb\") as f:\n",
    "        VDB_l2_noisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "613168c5-baa7-49ab-a8bb-53d89d65c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_noisy,\n",
    "        retriever_kgt1=VDB_l2_noisy,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "364ed139-397a-459e-bd88-3c47dab75d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        triviaqa_noisy_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f44ce7e1-9359-49f0-bddb-754be5128642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        triviaqa_noisy_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "834d1289-d2bd-4eea-ad15-1d4de1d8111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        triviaqa_noisy_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9877518e-4273-48bb-93f4-132d1fd6a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_4 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=4,return_context = True)\n",
    "        triviaqa_noisy_answers_4.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_4.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_4, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_4.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd930428-982b-453a-9bab-b62910eb9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_5 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=5,return_context = True)\n",
    "        triviaqa_noisy_answers_5.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_5.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_5, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_5.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33af9475-9b37-448c-9ef8-38bd5044d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_6 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=6,return_context = True)\n",
    "        triviaqa_noisy_answers_6.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_6.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_6, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_6.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faecc053-17c4-4625-af16-4b7b5127f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb91f89d31634e008d78b4d764ab44e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "399 / 1000\n",
      "Exact Match Score: 0.3990\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa = evaluate_answers(triviaqa_noisy_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{matches_triviaqa} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "beab4911-256d-4de9-8002-ade0324a28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8284c8cc68f1432bb31f91d63b5c0564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "463 / 1000\n",
      "Exact Match Score: 0.4630\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_2 = evaluate_answers(triviaqa_noisy_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{matches_triviaqa_2} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80eedddf-dfb5-492c-b25b-90368b2c5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809c6ee5fa1c422496054671f3123c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "487 / 1000\n",
      "Exact Match Score: 0.4870\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_3 = evaluate_answers(triviaqa_noisy_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{matches_triviaqa_3} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4875b6a8-3b59-43a9-a44e-dbedf9b3ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f5caec1adb455e8bf7254219ab23a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 4:\n",
      "500 / 1000\n",
      "Exact Match Score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_4 = evaluate_answers(triviaqa_noisy_answers_4,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 4:')\n",
    "print(f\"{matches_triviaqa_4} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_4 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ed0282f-a994-4a9a-b02a-1af9df91a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d15c2e4019a4756837a2077b330ef36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 5:\n",
      "496 / 1000\n",
      "Exact Match Score: 0.4960\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_5 = evaluate_answers(triviaqa_noisy_answers_5,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 5:')\n",
    "print(f\"{matches_triviaqa_5} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_5 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d056da6c-ec72-4444-8a58-edde383f7f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b137cdd4024a8aaee5a2b502a0f041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 6:\n",
      "493 / 1000\n",
      "Exact Match Score: 0.4930\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_6 = evaluate_answers(triviaqa_noisy_answers_6,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 6:')\n",
    "print(f\"{matches_triviaqa_6} / 1000\")\n",
    "print(f\"Exact Match Score: {matches_triviaqa_6 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c549ee-95bd-47e2-b5db-bd06b1ef80e3",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d9fa2-8237-406d-9fe0-ee2c8a75668e",
   "metadata": {},
   "source": [
    "We apply re-ranking to both experiments. First to the SQuAD dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a46f0-fec5-43f6-a2c4-a03ad45d8f81",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f35fd6-a529-41bb-8558-2d2aa06af5da",
   "metadata": {},
   "source": [
    "First evaluate if the context is found between the retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61c047d-07a1-4308-abdb-db744ba480b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cad569f000f4eb3b0eb91e5e12858db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5423483ac848f0924ef8f8d00e0f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset = dataset['validation']\n",
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )\n",
    "id_list = [doc.metadata['id'] for doc in docs_processed]\n",
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d61c122c-8f66-402e-a49b-c5ddae5d1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fa6e476-0de3-4216-a537-8a291ec5615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_1.pkl', 'rb') as f:\n",
    "        VDB_l2_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06f8bf25-031d-463d-ac60-a20701bad3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_1,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1dd3dc8-9001-45ff-b7fc-a8c02428393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Generating = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf717f01-7d5a-43fe-90b9-168e4f2a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    k_values = [1,2,3,4]\n",
    "    rerank_retrieve_results = []\n",
    "    # Iterate through the subset of questions\n",
    "    for row in tqdm(subset, desc=\"Evaluating questions\"):\n",
    "        question_id = row['id']\n",
    "        question_text = row['question']\n",
    "        actual_context = row['context']\n",
    "        # Evaluate for each k value\n",
    "        for k in k_values:\n",
    "            retrieved = rag_pipeline_with_rerank.retrieve_context(question_text,k=20)\n",
    "            retrieved_docs,scores = rag_pipeline_with_rerank.rerank_context(retrieved,k, question_text, return_scores = True)\n",
    "            found = any(doc == actual_context for doc in retrieved_docs)\n",
    "            rerank_retrieve_results.append({\n",
    "                \"question_id\": question_id,\n",
    "                \"question\": question_text,\n",
    "                \"actual_context\": actual_context,\n",
    "                \"k\": k,\n",
    "                \"retrieved_docs\": [doc for doc in retrieved_docs],\n",
    "                \"actual_context_found\": found,\n",
    "                \"scores\": scores,\n",
    "            })\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_retrieve_results.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_retrieve_results, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_retrieve_results.pkl', 'rb') as f:\n",
    "        rerank_retrieve_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cd83eab-4ddb-4492-a11e-5e17a8150ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "df_results = pd.DataFrame(rerank_retrieve_results)\n",
    "\n",
    "# Group by `k` and calculate the number of times the actual context was found\n",
    "summary_table = df_results.groupby(\"k\").agg(\n",
    "    times_context_found=(\"actual_context_found\", \"sum\"),\n",
    "    total_questions=(\"actual_context_found\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "# Add a column for the percentage of times the context was found\n",
    "summary_table[\"percentage_found\"] = (\n",
    "    summary_table[\"times_context_found\"] / summary_table[\"total_questions\"] * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c806d3b0-cee7-48fa-9982-fafb35f051aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>times_context_found</th>\n",
       "      <th>total_questions</th>\n",
       "      <th>percentage_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1894</td>\n",
       "      <td>2067</td>\n",
       "      <td>91.630382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>2067</td>\n",
       "      <td>95.839381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>2067</td>\n",
       "      <td>97.194001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>2067</td>\n",
       "      <td>97.387518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  times_context_found  total_questions  percentage_found\n",
       "0  1                 1894             2067         91.630382\n",
       "1  2                 1981             2067         95.839381\n",
       "2  3                 2009             2067         97.194001\n",
       "3  4                 2013             2067         97.387518"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "008a1a1e-7867-4f78-9494-db8ea20b9c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6eda907-24bb-4de2-b79b-8427adb3968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1)\n",
    "        rerank_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers.pkl', 'rb') as f:\n",
    "        rerank_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b504ba89-93bf-4c7d-8ed9-6cf8b71e5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        rerank_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers_2.pkl', 'rb') as f:\n",
    "        rerank_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4cb27fb-fafa-4513-a67b-8a6540d3339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        rerank_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers_3.pkl', 'rb') as f:\n",
    "        rerank_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20263ee2-b228-4229-bcbe-a724426401ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c6521f0-0b51-451f-99f7-d8064e18b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d481ddda9a4e7abaa98d7310fef62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1 and rerank:\n",
      "1334 / 2067\n",
      "Exact Match Score: 0.6454\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank = evaluate_answers(rerank_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1 and rerank:')\n",
    "print(f\"{exact_matches_rerank} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f14f451-8b02-4c48-97eb-1b6eea416289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f3e08c58924db18a494c04ab353839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2 and rerank:\n",
      "1279 / 2067\n",
      "Exact Match Score: 0.6188\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_2 = evaluate_answers(rerank_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2 and rerank:')\n",
    "print(f\"{exact_matches_rerank_2} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_2 / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6adcd881-a6df-43da-8c2c-39b46c00e342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5b80b0b6974fa391b08fc5c4ba5288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3 and rerank:\n",
      "1259 / 2067\n",
      "Exact Match Score: 0.6091\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_3 = evaluate_answers(rerank_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3 and rerank:')\n",
    "print(f\"{exact_matches_rerank_3} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_3 / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa14bc-928c-4a55-b17e-6f56342e1901",
   "metadata": {},
   "source": [
    "## With TriviaQA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5d051-6e1d-44f9-9e2c-d919fd92f10c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### With contexts dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5eef28c4-d9eb-4ab0-9c87-3faef10ac783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3431f258bc4ebc916696a10a0acbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream the validation split of TriviaQA (rc.wikipedia.nocontext configuration)\n",
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\", streaming=True)\n",
    "\n",
    "# Collect the first 1000 entries\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "\n",
    "# Convert the list to a Hugging Face Dataset\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30b241c5-d885-4178-9207-897fc946ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffa965829784bcd89226ddd57340f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entity pages:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LangchainDocument objects created (after deduplication): 1537\n"
     ]
    }
   ],
   "source": [
    "Raw_contexts = []\n",
    "\n",
    "unique_contents = set()\n",
    "\n",
    "for entry in tqdm(subset, desc=\"Processing entity pages\"):\n",
    "        entity_pages = entry[\"entity_pages\"]\n",
    "        for i, context in enumerate(entity_pages[\"wiki_context\"]):\n",
    "            if context not in unique_contents:\n",
    "                unique_contents.add(context)\n",
    "                Raw_contexts.append(\n",
    "                    LangchainDocument(\n",
    "                        page_content=context,\n",
    "                        metadata={\n",
    "                            \"title\": entity_pages[\"title\"][i],\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "# Verify the result\n",
    "print(f\"Total LangchainDocument objects created (after deduplication): {len(Raw_contexts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45515659-26c8-4d9e-8670-cfdfc9cfa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4376799a-bd20-4e06-9cad-266beb076069",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Raw_contexts,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "        docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6966786b-b8ec-48e1-8739-aed010f0e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 20000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ccf0867-f67d-4081-a5d7-1e9c874bf05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (111999, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fac81aef-be45-4fc3-8d6c-6ad93bb719af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    index.add(embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_contexts = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_contexts.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_contexts, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_contexts.pkl\", \"rb\") as f:\n",
    "        VDB_l2_contexts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6c6f7ed-6732-469d-8d48-3ce0e108172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_contexts,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90589c9a-3abc-4b05-b58a-5761b0dde490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1,return_context = True)\n",
    "        triviaqa_rerank_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50b28b45-fb07-41fb-ba39-8cf8f30bb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        triviaqa_rerank_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "120a1154-8b4c-4e43-9127-add6cf83029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        triviaqa_rerank_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "271793b6-417c-4b6a-8b55-ddf9a306cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ca0a05a-83e9-46d3-9b8b-d8c011ebb1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd23ce0e29e14e27a24678c769fb154c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "547 / 1000\n",
      "Exact Match Score: 0.5470\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank = evaluate_answers(triviaqa_rerank_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_rerank} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a9e9f18-2cd5-401e-9013-c348ed6087e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c8e5198f2542b3886bea31bb86e496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "554 / 1000\n",
      "Exact Match Score: 0.5540\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_2 = evaluate_answers(triviaqa_rerank_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_rerank_2} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c61af53c-9cc1-4481-a7da-6175088cfd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d08e2bf04546bbb306b0f918a86743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "554 / 1000\n",
      "Exact Match Score: 0.5540\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_3 = evaluate_answers(triviaqa_rerank_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_rerank_3} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97911d71-7bc0-41a0-8b7e-73ae0afa9193",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### With Additional contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78fc65-93ec-4a43-a96f-3bb8cbbc8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977cf2a-67b1-4146-a0e9-b873f0543772",
   "metadata": {},
   "outputs": [],
   "source": [
    "Additional_documents = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf956c-3eb6-4e55-9cf5-885d47838deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7050927-f78e-4a7b-b0c2-010a10de53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed_2 = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Additional_documents,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed_2, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed_2.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed_2, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed_2.pkl\", \"rb\") as f:\n",
    "        docs_processed_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e9406-8304-492a-8bc6-7d56da4fcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define output directory\n",
    "    output_dir = \"embeddings_2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define batch size\n",
    "    batch_size = 100000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue  # Skip already processed batches\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            # Initialize embeddings for the batch\n",
    "            batch_embeddings = []\n",
    "            \n",
    "            # Compute embeddings with progress tracking within the batch\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            \n",
    "            # Convert batch embeddings to numpy array\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            \n",
    "            # Save the batch to a file\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c153ea8-f662-4a3a-aa50-d5efe5bbb9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings_2\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings_2 = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings_2.shape}\")\n",
    "embeddings_2 = embeddings_2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76529726-95e2-4a5c-9d9b-90994c268d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    # Define the embedding dimension and FAISS index\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    # Add precomputed embeddings to the FAISS index\n",
    "    all_embeddings = np.concatenate([embeddings, embeddings_2]).astype(np.float32)\n",
    "    index.add(all_embeddings)\n",
    "    # Convert metadata to Document objects\n",
    "    all_docs = docs_processed + docs_processed_2\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(all_docs)}\n",
    "    # Create the docstore\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    # Create a mapping from FAISS IDs to docstore IDs\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_noisy = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_noisy.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_noisy, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_noisy.pkl\", \"rb\") as f:\n",
    "        VDB_l2_noisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df56fd52-29f4-4a0b-9ed2-5eac9f503256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_noisy,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8d48555f-5933-42ed-a8f0-5ce876c56715",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85493e4f-a0af-4f0f-b827-3dd017d90c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers_2 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "585f0767-2c20-4a50-b840-f13e5346f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers_3 = []\n",
    "    # Iterate through the subset with tqdm for progress tracking\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bba61c9-ac25-45ee-810b-98eca4615df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd671bbe-e4af-4e38-9b25-dc4b3fc902f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d256efd0c41845eebda5847ce7ac9c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "553 / 1000\n",
      "Exact Match Score: 0.5530\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy = evaluate_answers(triviaqa_rerank_noisy_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_rerank_noisy} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_noisy / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8eee6a69-04d0-4c3f-85ca-46a8c1d3c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77212ee9aa124c87808c6c22bd044cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "563 / 1000\n",
      "Exact Match Score: 0.5630\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy_2 = evaluate_answers(triviaqa_rerank_noisy_answers_2,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_rerank_noisy_2} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_noisy_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad4e9030-f3dd-4551-82f4-fe549b87044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9365c0c093346d0be351f1a1cea83d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "558 / 1000\n",
      "Exact Match Score: 0.5580\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy_3 = evaluate_answers(triviaqa_rerank_noisy_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_rerank_noisy_3} / 1000\")\n",
    "print(f\"Exact Match Score: {exact_matches_rerank_noisy_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae6f85-eb7b-4897-a2ac-3d7d3f9c0422",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Natural questions. Wikipedia Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbbcc181-96dd-4029-a4e4-20b117d6b75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5d780eb-2f00-4b3a-829d-f6c2d9d10884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 205328/205328 [00:08<00:00, 23212.30it/s]\n"
     ]
    }
   ],
   "source": [
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"url\": doc[\"url\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faecfda2-52a3-4829-8b13-b58fc3698ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c100a06-fe1e-43f9-a533-19069c8c76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n\\n\",  # Paragraph breaks\n",
    "    \"\\n\",    # Line breaks\n",
    "    \". \",    # Sentence endings\n",
    "    \"? \",    # Question endings\n",
    "    \"! \",    # Exclamation endings\n",
    "    \" \",     # Fallback to spaces\n",
    "    \"\"       # Catch-all\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75656ca0-c1a4-440e-bf79-c319853e518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45e3c1cf-bc06-4a20-b578-fa3237af6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save docs_processed to a file\n",
    "with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs_processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69907955-121b-4e41-8bb6-74be7cf7ba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs_processed from a file\n",
    "with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "    docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7a5ce-97f7-4ba1-bd97-991c44983160",
   "metadata": {},
   "source": [
    "Create the answers (Used colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c22941-bd79-4ba7-9cdd-506c6c72a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory\n",
    "output_dir = \"embeddings\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 100000\n",
    "\n",
    "# Get already processed batches (for resuming)\n",
    "processed_batches = {\n",
    "    int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "}\n",
    "\n",
    "# Process documents in batches\n",
    "num_docs = len(docs_processed)\n",
    "for start_idx in range(0, num_docs, batch_size):\n",
    "    batch_number = start_idx // batch_size\n",
    "    if batch_number in processed_batches:\n",
    "        continue  # Skip already processed batches\n",
    "    \n",
    "    # Define end index for the current batch\n",
    "    end_idx = min(start_idx + batch_size, num_docs)  # Handles the last smaller batch\n",
    "    batch_docs = docs_processed[start_idx:end_idx]\n",
    "    \n",
    "    try:\n",
    "        # Initialize embeddings for the batch\n",
    "        batch_embeddings = []\n",
    "        \n",
    "        # Compute embeddings with progress tracking within the batch\n",
    "        for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "            batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "        \n",
    "        # Convert batch embeddings to numpy array\n",
    "        batch_embeddings = np.array(batch_embeddings)\n",
    "        \n",
    "        # Save the batch to a file\n",
    "        batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "        np.save(batch_file, batch_embeddings)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch {batch_number}: {e}\")\n",
    "        # Save progress in case of an error\n",
    "        with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "            log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e112056-ca32-4480-b938-76482d49732d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where batches are saved\n",
    "output_dir = \"embeddings\"\n",
    "# Get a list of all saved batch files, sorted by batch number\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce71c3cc-2f50-4190-9908-190b3e0a9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# Define the embedding dimension and FAISS index\n",
    "embedding_dim = 384  \n",
    "index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "# Add precomputed embeddings to the FAISS index\n",
    "index.add(embeddings)\n",
    "# Convert metadata to Document objects\n",
    "metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "# Create the docstore\n",
    "docstore = InMemoryDocstore(metadata)\n",
    "# Create a mapping from FAISS IDs to docstore IDs\n",
    "index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "\n",
    "# Initialize the FAISS vector store\n",
    "VDB_l2 = FAISS(\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    "    embedding_function=embedding_function\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6af86-6d26-4fd5-8d3c-4d2924b4b93d",
   "metadata": {},
   "source": [
    "We have the vector database, now get the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c4dbcd0-5348-4de8-a447-06915abf0b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10570/10570 [00:01<00:00, 6489.06it/s]\n",
      "Processing documents: 100%|██████████████████████████████████████████████████| 10570/10570 [00:00<00:00, 316676.74it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset = dataset['validation']\n",
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )\n",
    "id_list = [doc.metadata['id'] for doc in docs_processed]\n",
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77a877a-b1d6-4b27-b9e2-80c80e1c7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2,\n",
    "        retriever_kgt1=VDB_l2,\n",
    "        device=\"cpu\"  # Use \"cuda\" for GPU or \"cpu\" for CPU\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb1a63-383c-4ad0-baa9-a23b3fb1fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_answers = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "    wikipedia_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/wikipedia_answers.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79080eb0-cc8d-4f64-aa9b-5a611db137bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_answers_2 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer = rag_pipeline.generate_answer(question,k=2)\n",
    "    wikipedia_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/wikipedia_answers_2.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia_answers_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c39e0e-eb0f-4b9d-981c-8834ebe2780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia_answers_3 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "    wikipedia_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/wikipedia_answers_3.pkl', 'wb') as f:\n",
    "    pickle.dump(wikipedia_answers_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41940fe5-0df1-42c1-ab57-469f746a22de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/wikipedia_answers.pkl', 'rb') as f:\n",
    "    wikipedia_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a2be9da-fc2f-4959-a9b0-95333f059295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 2067/2067 [00:00<00:00, 3116.70question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "111 / 2067\n",
      "Exact Match Score: 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_wiki = evaluate_answers(wikipedia_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_wiki} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_wiki / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eea4247a-4deb-45f8-b969-115cab6ece55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the Pickle file\n",
    "with open('PKL files/wikipedia_answers_2.pkl', 'rb') as f:\n",
    "    wikipedia_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc0eb1f7-2536-466e-87a8-1c8729941ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 2067/2067 [00:00<00:00, 2989.89question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "123 / 2067\n",
      "Exact Match Score: 0.0595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Exact Matches with Tokenization\n",
    "exact_matches_wiki_2 = evaluate_answers(wikipedia_answers_2,tokenizer)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_wiki_2} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_wiki_2 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ab35c02-2b6d-4830-8f4b-df4c5972a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the Pickle file\n",
    "with open('PKL files/wikipedia_answers_3.pkl', 'rb') as f:\n",
    "    wikipedia_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26819d1a-e742-4a2a-be81-43b5b044cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 2067/2067 [00:00<00:00, 3279.98question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "136 / 2067\n",
      "Exact Match Score: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_wiki_3 = evaluate_answers(wikipedia_answers_3,tokenizer)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_wiki_3} / 2067\")\n",
    "print(f\"Exact Match Score: {exact_matches_wiki_3 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2eeec-2467-4505-9369-9f2e19e2f9ff",
   "metadata": {},
   "source": [
    "New questions dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cddbd1a-c545-4e4c-9d78-43b7ebead989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689b4b64be8440009e5a6f7cc5c3e0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream the validation split of TriviaQA (rc.wikipedia.nocontext configuration)\n",
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia.nocontext\", split=\"validation\", streaming=True)\n",
    "\n",
    "# Collect the first 1000 entries\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "\n",
    "# Convert the list to a Hugging Face Dataset\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset = subset.remove_columns(['question_source', 'entity_pages', 'search_results'])\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7266e5bf-3f31-46d6-a13a-855fdd14c490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunset Blvd',\n",
       " 'West Sunset Boulevard',\n",
       " 'Sunset Boulevard',\n",
       " 'Sunset Bulevard',\n",
       " 'Sunset Blvd.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0]['answer']['aliases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d0618b-e108-4a22-884b-4e2954280556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|████████████████████████████████████████████████████| 1000/1000 [09:37<00:00,  1.73question/s]\n"
     ]
    }
   ],
   "source": [
    "triviaqa_answers = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "    triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/triviaqa_answers.pkl', 'wb') as f:\n",
    "    pickle.dump(triviaqa_answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa18bb0-9094-4c9c-a071-cd2bb2eeacaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/triviaqa_answers.pkl', 'rb') as f:\n",
    "    triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d8f6ac-feb3-4bfb-b20b-eef16a3d0f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|████████████████████████████████████████████████████| 1000/1000 [10:34<00:00,  1.58question/s]\n"
     ]
    }
   ],
   "source": [
    "triviaqa_answers_2 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "    triviaqa_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/triviaqa_answers_2.pkl', 'wb') as f:\n",
    "    pickle.dump(triviaqa_answers_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3e28eeb-db96-4ef5-9388-b4284bd08a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/triviaqa_answers_2.pkl', 'rb') as f:\n",
    "    triviaqa_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f12d7807-41db-4593-aa6b-a98c81c4a889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|████████████████████████████████████████████████████| 1000/1000 [16:14<00:00,  1.03question/s]\n"
     ]
    }
   ],
   "source": [
    "triviaqa_answers_3 = []\n",
    "# Iterate through the subset with tqdm for progress tracking\n",
    "for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "    question = subset[i]['question']\n",
    "    answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "    triviaqa_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "# Save the dictionary to a Pickle file\n",
    "with open('PKL files/triviaqa_answers_3.pkl', 'wb') as f:\n",
    "    pickle.dump(triviaqa_answers_3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd291e8d-af70-45f8-8e9f-a82fd7abcf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PKL files/triviaqa_answers_3.pkl', 'rb') as f:\n",
    "    triviaqa_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "894a9ae7-a59c-4abe-9db6-4c4a95fdce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|███████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 444.36question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "289 / 1000\n",
      "Exact Match Score: 0.2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_triviaqa_1 = evaluate_answers(triviaqa_answers,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_triviaqa_1} / {len(triviaqa_answers)}\")\n",
    "print(f\"Exact Match Score: {exact_matches_triviaqa_1 / len(triviaqa_answers):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4dba622-542a-4ce6-bc72-ac912d4827ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 1262.30question/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "309 / 1000\n",
      "Exact Match Score: 0.3090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "exact_matches_triviaqa_2,errors = evaluate_answers(triviaqa_answers_2,tokenizer,return_errors = True)\n",
    "\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_triviaqa_2} / {len(triviaqa_answers_2)}\")\n",
    "print(f\"Exact Match Score: {exact_matches_triviaqa_2 / len(triviaqa_answers_2):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525e3825-dbc1-49e6-a457-b4b02a57ceb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|███████████████████████████████████████████████████| 1000/1000 [00:02<00:00, 465.00question/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "302 / 1000\n",
      "Exact Match Score: 0.3020\n"
     ]
    }
   ],
   "source": [
    "exact_matches_triviaqa_3 = evaluate_answers(triviaqa_answers_3,tokenizer)\n",
    "# Print results\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_triviaqa_3} / {len(triviaqa_answers_3)}\")\n",
    "print(f\"Exact Match Score: {exact_matches_triviaqa_3 / len(triviaqa_answers_3):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b16d4f5a-06f0-4d04-b4ed-f9cae8c5fcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'tc_538',\n",
       " 'question': 'In the 80s who wrote the novel Empire of The Sun?',\n",
       " 'answer': 'Ballard',\n",
       " 'ground_truths': ['JG Ballard',\n",
       "  'J.G. Ballard',\n",
       "  'James Graham Ballard',\n",
       "  'J. G. Ballard',\n",
       "  'J.G.Ballard',\n",
       "  'Jg ballard',\n",
       "  \"A User's Guide to the Millenium\",\n",
       "  'J G Ballard',\n",
       "  'Ballardian',\n",
       "  'James G. Ballard'],\n",
       " 'context': 'The 1980s and later\\n\\nJames Graham Ballard (often \"Jim\"; 15 November 1930 – 19 April 2009) was an English novelist, short story writer, and important member of the New Wave movement in science fiction. His best-known books are  Crash (1973) and Empire of the Sun (1984).\\n\\nLife'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triviaqa_answers_2[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c396ade2-5aa4-4d5a-b40f-989d96764d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Lloyd Webber musical premiered in the US on 10th December 1993?\n",
      "Model answer:  mr. wilson\n",
      "Ground truth:  Sunset Blvd\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Musicals\n",
      "\n",
      "Release dates \n",
      "\n",
      "1993 comedy movies\n",
      "1990s musical movies\n",
      "American musical comedy movies\n",
      "---------------------------------------------------------------------------\n",
      "Who was the next British Prime Minister after Arthur Balfour?\n",
      "Model answer:  Balfour\n",
      "Ground truth:  Sir Henry Campbell-Bannerman\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Arthur James Balfour, 1st Earl of Balfour, KG OM PC (25 July 1848 – 19 March 1930) was a British Conservative statesman and Prime Minister of the United Kingdom from 1902 until 1905.\n",
      "\n",
      "He was minister of Foreign Affairs from 1916 to 1919. In this capacity he wrote the so-called Balfour Declaration in 1917.\n",
      "\n",
      "1848 births\n",
      "1930 deaths\n",
      "Former Conservative Party (UK) MPs\n",
      "Government ministers\n",
      "Knights of the Garter\n",
      "Order of Merit\n",
      "Members of the Privy Council of the United Kingdom\n",
      "United Kingdom Earls\n",
      "Zionists\n",
      "\n",
      "List of prime ministers \n",
      "\n",
      "Politics of the United Kingdom\n",
      "---------------------------------------------------------------------------\n",
      "Who had a 70s No 1 hit with Kiss You All Over?\n",
      "Model answer:  Dr. Love Ladies Room\n",
      "Ground truth:  Internal exile\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Rock and Roll Over is the fifth studio album and sixth album overall by the American hard rock/heavy metal band Kiss. It was released on November 11, 1976.\n",
      "\n",
      "Track listing \n",
      "I Want You\n",
      "Take Me\n",
      "Calling Dr. Love\n",
      "Ladies Room\n",
      "Baby Driver\n",
      "Love 'Em and Leave 'Em\n",
      "Mr. Speed\n",
      "See You in Your Dreams\n",
      "Hard Luck Woman\n",
      "Makin' Love\n",
      "\n",
      "Kiss albums\n",
      "1976 albums\n",
      "Hard rock albums\n",
      "Heavy metal albums\n",
      "\n",
      "Kiss career\n",
      "---------------------------------------------------------------------------\n",
      "Which actress was voted Miss Greenwich Village in 1942?\n",
      "Model answer:  sarah wilson\n",
      "Ground truth:  Bacall\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "1942 births\n",
      "Living people\n",
      "American fashion designers\n",
      "Businesspeople from New York City\n",
      "\n",
      "1942 births\n",
      "Living people\n",
      "American judges\n",
      "Lawyers from New York City\n",
      "Jewish American entertainers\n",
      "Jewish American writers\n",
      "Jewish judges\n",
      "Jewish lawyers\n",
      "Television personalities from New York City\n",
      "Writers from Brooklyn\n",
      "Women judges\n",
      "---------------------------------------------------------------------------\n",
      "What was the name of Michael Jackson's autobiography written in 1988?\n",
      "Model answer:  Michael Jackson\n",
      "Ground truth:  Walk on the Moon\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "References\n",
      "\n",
      "1988 movies\n",
      "Michael Jackson\n",
      "American superhero movies\n",
      "\n",
      "Michael Jackson\n",
      "---------------------------------------------------------------------------\n",
      "Which volcano in Tanzania is the highest mountain in Africa?\n",
      "Model answer:  Mount Kenya\n",
      "Ground truth:  Mawensi\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Mount Kenya is the highest mountain in Kenya. It is  high. It is the second highest mountain in Africa. It is an extinct volcano. It is on the equator. It is  northeast of Nairobi.\n",
      "\n",
      "References\n",
      "\n",
      "Geography of Kenya\n",
      "Mountains of Africa\n",
      "\n",
      "Tanzania\n",
      "---------------------------------------------------------------------------\n",
      "The flag of Libya is a plain rectangle of which color?\n",
      "Model answer:  red\n",
      "Ground truth:  Greenishly\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The Flag of Libya has three horizontal stripes of red, black, and green, with a white crescent and star in the center of the black stripe.  It has been the official flag of Libya since 3 August 2011.\n",
      "\n",
      "Overview \n",
      "The flag is the same as the flag of the earlier Kingdom of Libya, used from 1951 to 1969.  During the dictatorship of Muammar al-Gaddafi the flag was changed twice and it was just a plain field of green. It was unique for being the only national flag in the world with just one color and no design, emblems, coat of arms, or any other details. It was adopted on 11 November 1977.\n",
      "\n",
      "Related pages\n",
      "Flag of Libya (1977–2011)\n",
      "\n",
      "References \n",
      "\n",
      "Libya\n",
      "Libya\n",
      "1951 establishments\n",
      "1969 disestablishments\n",
      "2011 establishments\n",
      "---------------------------------------------------------------------------\n",
      "Which musical featured the song The Street Where You Live?\n",
      "Model answer:  Musicals\n",
      "Ground truth:  My Fair Lady (2010 film)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Musicals\n",
      "\n",
      "The musical opened in 1980 in Paris. In 1985, it opened in London's West End. In 1987, it opened on Broadway. It won a Tony Award for Best Musical, and a Drama Desk Award for Outstanding Musical. In 2012, it was adapted to a movie starring Hugh Jackman, Russell Crowe, and Anne Hathaway.\n",
      "\n",
      "1980s musicals\n",
      "Broadway musicals\n",
      "Fiction set in the past\n",
      "Musicals adapted to movies\n",
      "Musicals based on books\n",
      "Tony Award winning musicals\n",
      "West End musicals\n",
      "---------------------------------------------------------------------------\n",
      "Who had an 80s No 1 hit with Hold On To The Nights?\n",
      "Model answer:  Ariola\n",
      "Ground truth:  Richard Noel Marx\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Singles\n",
      "\"Hide Away – Man Is Coming'!\" (1985, Ariola)\n",
      "\"Touch in the Night\" (1985, Ariola)\n",
      "\"Stop the Rain\" / \"Shy Girl\" (1986, ZYX Music)\n",
      "\"Love Is Just a Word\" (1986)\n",
      "\"Time for Love\" (1986)\n",
      "\"Danger Danger\" (1987)\n",
      "\"Oh, Don't Lose Your Heart Tonight\" (1987)\n",
      "\n",
      ". He also performed the songs \"I'm Alright\" (peaked at #7 in the U.S.), \"Mr. Night\" and \"Lead the Way\" from Caddyshack (1980), and \"Meet Me Half Way\" from Over the Top (1987).\n",
      "---------------------------------------------------------------------------\n",
      "Who directed the classic 30s western Stagecoach?\n",
      "Model answer:  United Artists\n",
      "Ground truth:  John Ford (1895-1973)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Stagecoach is a 1939 American western movie directed by John Ford and was based on the 1937 short story The Stage to Lordsburg by Ernest Haycox. It stars John Wayne, Claire Trevor, Andy Devine, John Carradine, Thomas Mitchell, Louise Platt, George Bancroft and was distributed by United Artists. It was nominated for 7 Academy Awards and won 2 in 1940 and was remade as Stagecoach in 1966 and 1986.\n",
      "\n",
      "Other websites\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "1939 movies\n",
      "1930s western movies\n",
      "American western movies\n",
      "Movies based on short stories\n",
      "Movies directed by John Ford\n",
      "\n",
      "Stagecoach to Fury is a 1956 American western movie directed by William F. Claxton and starring Forrest Tucker, Mari Blanchard, Wallace Ford, Paul Fix, Wright King, Ellen Corby, Rayford Barnes. It was distributed by 20th Century Fox.\n",
      "\n",
      "Other websites\n",
      "\n",
      "1956 movies\n",
      "1950s western movies\n",
      "American western movies\n",
      "Movies directed by William F. Claxton\n",
      "---------------------------------------------------------------------------\n",
      "Which highway was Revisited in a classic 60s album by Bob Dylan?\n",
      "Model answer:  The Danger Zone\n",
      "Ground truth:  61\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "In this context, \"hit the road\" is an idiom meaning \"get lost,\" as the following words indicate.\n",
      "\n",
      "Recording Details\n",
      "For the most popular recording\n",
      " Title: \"Hit the Road Jack\"\n",
      " Artist: Single by Ray Charles\n",
      " B-side: \"The Danger Zone\"\n",
      " Released: September 1961\n",
      " Format: 7\", 45rpm\n",
      " Genre: R&B\n",
      " Length: 2:00\n",
      " Label: ABC\n",
      " Writer(s): Percy Mayfield\n",
      "\n",
      "1961 songs\n",
      "R&B songs\n",
      "\n",
      "Studio albums\n",
      "\n",
      "Live albums\n",
      "\n",
      "Soundtracks\n",
      "\n",
      "Compilations\n",
      "\n",
      "Collaborations with Bob Dylan\n",
      "\n",
      "Singles\n",
      "\n",
      "References\n",
      "---------------------------------------------------------------------------\n",
      "Which was the only eastern bloc country to participate in the 1984 LA Olympics?\n",
      "Model answer:  Yugoslavia\n",
      "Ground truth:  ISO 3166-1:RO\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The 1984 Olympics could mean:\n",
      "The 1984 Summer Olympics in Los Angeles, United States\n",
      "The 1984 Winter Olympics in Sarajevo, Yugoslavia\n",
      "\n",
      "The 1984 Summer Olympics, officially known as the Games of the XXIII Olympiad, were held in Los Angeles, United States from July 28 to August 12.\n",
      "\n",
      "1984 Summer Olympics\n",
      "---------------------------------------------------------------------------\n",
      "Which 90s sci fi series with James Belushi was based on Bruce Wagner's comic strip of the same name?\n",
      "Model answer:  Marvel Comics\n",
      "Ground truth:  Wild Palms\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Fictional universes\n",
      "Marvel Comics\n",
      "\n",
      "Comic book\n",
      "---------------------------------------------------------------------------\n",
      "If I Were A Rich Man Was a big hit from which stage show?\n",
      "Model answer:  saturday night\n",
      "Ground truth:  Fiddler on a Roof\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Famous concerts\n",
      "\n",
      "Musicals\n",
      "Elton John\n",
      "---------------------------------------------------------------------------\n",
      "Men Against the Sea and Pitcairn's Island were two sequels to what famous novel?\n",
      "Model answer:  Men Against the Sea\n",
      "Ground truth:  HMS Bounty mutineers\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Pitcairn Island\n",
      "\n",
      "Shipwreck Island is the second book of the trilogy written by Struan Murray and first published on March 4, 2021.\n",
      "\n",
      "References \n",
      "\n",
      "2021 books\n",
      "Children's books\n",
      "Fantasy books\n",
      "---------------------------------------------------------------------------\n",
      "What was Truman Capote's last name before he was adopted by his stepfather?\n",
      "Model answer:  Corozzo\n",
      "Ground truth:  Perſons\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Truman Capote (born Truman Streckfus Persons, September 30, 1924 - August 25, 1984) was an American author. He was born in New Orleans, Louisiana and grew up in Monroeville, Alabama, New York City and Greenwich, Connecticut. He is best known for writing the half-true novel, In Cold Blood. The novel is based on a murder that happened in Kansas in the 1950s. He became good friends with the man accused of the murder.\n",
      "\n",
      "Capote was openly gay. He died of liver cancer in Los Angeles, California, aged 59.\n",
      "\n",
      "References\n",
      "\n",
      "Current family Capos \n",
      " Nicholas \"Little Nick\" Corozzo - Capo and Boss of the Gambino crime family. Brother of Consigliere Joseph Corozzo, uncle of Joseph Jr. and the current head of the caporegimes. Became a fugitive for almost four months, currently incarcerated.\n",
      "---------------------------------------------------------------------------\n",
      "In Lewis Carroll's poem The Hunting of the Snark, what did the elusive, troublesome snark turn into to fool hunters?\n",
      "Model answer:  Sylvie and Bruno\n",
      "Ground truth:  Boojum (disambiguation)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The Hunting of the Snark (An Agony in 8 Fits) is a nonsense poem written by Lewis Carroll, the pen name of Charles Lutwidge Dodgson.\n",
      "\n",
      "The Hunting of the Snark (1876)\n",
      " Rhyme? and Reason? (1883) A collection of poems, including Phantasmagoria and The Hunting of the Snark\n",
      " A Tangled Tale (1886)\n",
      " Sylvie and Bruno (1889)\n",
      " Sylvie and Bruno Concluded (1893)\n",
      " Three Sunsets and other poems\n",
      " What the Tortoise said to Achilles (1895)\n",
      "---------------------------------------------------------------------------\n",
      "Art Garfunkel trained for which profession although he didn't qualify?\n",
      "Model answer:  singer\n",
      "Ground truth:  Master Builder (occupation)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Art Garfunkel (born November 5, 1941) is an American singer of Jewish descent. Along with Paul Simon, he was part of the duo Simon and Garfunkel, a popular group in the 1960s and early 1970s. After that, he made several solo albums. He has also acted in a few movies.\n",
      "\n",
      "Career before becoming a professional\n",
      "---------------------------------------------------------------------------\n",
      "In the 80s who wrote the novel Empire of The Sun?\n",
      "Model answer:  Ballard\n",
      "Ground truth:  JG Ballard\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "The 1980s and later\n",
      "\n",
      "James Graham Ballard (often \"Jim\"; 15 November 1930 – 19 April 2009) was an English novelist, short story writer, and important member of the New Wave movement in science fiction. His best-known books are  Crash (1973) and Empire of the Sun (1984).\n",
      "\n",
      "Life\n",
      "---------------------------------------------------------------------------\n",
      "Kim Carnes' nine weeks at No 1 with Bette Davis Eyes was interrupted for one week by which song?\n",
      "Model answer:  Bette Davis Eyes\n",
      "Ground truth:  Stars on 45 (Single)\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Kim Carnes (born 20 July 1945) is an American singer. She is best known for the song \"Bette Davis Eyes\" (1981).\n",
      "Bette Davis liked the song.  Carnes gave Davis a gold record.  Bette Davis hung the gold record on a wall.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      " Kim Carnes - Official Web Site\n",
      " Kim Carnes Fan Club Web Site\n",
      " \n",
      "\n",
      "American folk musicians\n",
      "Singers from Los Angeles\n",
      "American pop musicians\n",
      "Singer-songwriters from California\n",
      "Grammy Award winners\n",
      "1945 births\n",
      "Living people\n",
      "Country musicians\n",
      "\n",
      "In 1981 Kim Carnes sang the hit song \"Bette Davis Eyes\". Davis liked the song. Carnes gave Davis a gold record. Davis hung the gold record on a wall.\n",
      "\n",
      "The Kennedy Center honored Davis in 1987. She died of breast cancer in Neuilly-sur-Seine, France.\n",
      "\n",
      "Other websites \n",
      " Bette Davis at Classic Actresses \n",
      " Classic Movies (1939 - 1969): Bette Davis\n",
      "\n",
      "Sources\n",
      "---------------------------------------------------------------------------\n",
      "What was Walter Matthau's first movie?\n",
      "Model answer:  The Odd Couple II\n",
      "Ground truth:  The Kentuckian\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Walter Matthau (October 1, 1920–July 1, 2000) was an American actor. He starred with Jack Lemmon in The Odd Couple and its sequel The Odd Couple II. He won the Academy Award for The Fortune Cookie.\n",
      "\n",
      "First movies\n",
      "---------------------------------------------------------------------------\n",
      "Which musician founded the Red Hot Peppers?\n",
      "Model answer:  Anthony Kiedis\n",
      "Ground truth:  Ferdinand Joseph La Menthe\n",
      "--------------------------------------\n",
      " Retrieved context:\n",
      "Band history\n",
      "\n",
      "Creation \n",
      "Red Hot Chili Peppers were originally called Tony Flow and the Miraculously Majestic Masters of Mayhem. The band was started in 1983 for a single performance. They were so popular that they were asked to come back again the next week. The first members of the band were Anthony Kiedis (singer), Flea (bass), Hillel Slovak (guitar), and Jack Irons (drums). They all knew each other from Fairfax High School in Los Angeles.\n",
      "\n",
      "For the pepper, see Chilli pepper.\n",
      "Red Hot Chili Peppers are an American rock band. The band started in 1983 in Los Angeles, California. The state of California has been a theme in many of their songs. The members of the band are singer Anthony Kiedis, bass guitarist Flea, guitarist John Frusciante, and drummer Chad Smith.\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in errors:\n",
    "    print(triviaqa_answers_2[index]['question'])\n",
    "    print('Model answer: ',triviaqa_answers_2[index]['answer'])\n",
    "    print('Ground truth: ',triviaqa_answers_2[index]['ground_truths'][0])\n",
    "    print('--------------------------------------\\n','Retrieved context:')\n",
    "    print(triviaqa_answers_2[index]['context'])\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    if index>30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79259c6-1bf7-483d-b2ae-2d96c973efa3",
   "metadata": {},
   "source": [
    "# Wikipedia retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3ea36-7f94-4c0a-a413-28c8ac483e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51429d-7675-4021-83fc-834e0a915376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4973c6d4-7620-4c42-9df6-c0dfac05dc7c",
   "metadata": {},
   "source": [
    "We will start by coding a Naive RAG. We will use documents from a small Wikipedia dataset, and apply it to question solving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01ebd9-22f8-4066-84bf-788ce5b7824c",
   "metadata": {},
   "source": [
    "First of all, we have to design a retriever for our database. We will preprocess the text to divide it in chunks, and then embed every chunk using a vectorizer, and store them in a vector database (our dataset is already preprocessed). To retrieve them, the query is embedded in the same way and compared with cosine similarity to all the documents in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce27c42c-4293-4438-8ff0-d29fc06e3a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = \"avsolatorio/NoInstruct-small-Embedding-v0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126dcfb4-32ea-4829-92df-a5e44b45960a",
   "metadata": {},
   "source": [
    "## Creating the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c366104-0cd0-4eed-817d-813b3d33a1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['passage', 'id'],\n",
       "    num_rows: 3200\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"rag-datasets/rag-mini-wikipedia\", \"text-corpus\")\n",
    "ds = ds['passages']\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb6ece2-b942-4665-b53c-6bd673a2a509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the Wikipedia dataset\n",
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,  # Allow execution of custom code\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a579da5b-e177-4713-ab93-4f241214c53f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# ds_train = ds[\"train\"]\n",
    "# chunk_size = 100000\n",
    "\n",
    "# for i in range(0, len(ds_train), chunk_size):\n",
    "#     end = min(i + chunk_size, len(ds_train))\n",
    "#     # Use select() to get a Dataset object with the specified range of rows\n",
    "#     subset = ds_train.select(range(i, end))\n",
    "#     print(type(subset))  # Should show <class 'datasets.arrow_dataset.Dataset'>\n",
    "\n",
    "#     chunk_docs = [\n",
    "#         LangchainDocument(\n",
    "#             page_content=doc[\"text\"],\n",
    "#             metadata={\n",
    "#                 \"id\": doc[\"id\"],\n",
    "#                 \"title\": doc[\"title\"],\n",
    "#                 \"url\": doc[\"url\"]\n",
    "#             }\n",
    "#         )\n",
    "#         for doc in subset\n",
    "#     ]\n",
    "\n",
    "#     with open(f\"raw_knowledge_base_chunk_{i}.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(chunk_docs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e8015a-16ef-488d-a489-151f7411e50e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import pickle\n",
    "# RAW_KNOWLEDGE_BASE = []\n",
    "# i=0\n",
    "# for file_path in sorted(glob.glob(\"raw_knowledge_base_chunk_*.pkl\")):\n",
    "#     i+=1\n",
    "#     with open(file_path, \"rb\") as f:\n",
    "#         chunk_docs = pickle.load(f)  # This returns a list of LangchainDocument objects\n",
    "#         RAW_KNOWLEDGE_BASE.extend(chunk_docs)\n",
    "#     print('loaded',i)\n",
    "\n",
    "# print(f\"Total documents loaded: {len(RAW_KNOWLEDGE_BASE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70761d1d-fdfd-475b-ad90-10fd3a2b92b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5b8e1638f048ce93e39c50b7ddc984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# RAW_KNOWLEDGE_BASE = [\n",
    "#     LangchainDocument(\n",
    "#         page_content=doc[\"passage\"],\n",
    "#         metadata={\n",
    "#             \"id\": doc[\"id\"]\n",
    "#         }\n",
    "#     )\n",
    "#     for doc in tqdm(ds)\n",
    "# ]\n",
    "\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "            \"title\": doc[\"title\"],\n",
    "            \"url\": doc[\"url\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff616fd6-85fe-493b-a3dd-8535f47192ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # After creation:\n",
    "# with open(\"raw_knowledge_base.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(RAW_KNOWLEDGE_BASE, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fec9a9a-1d99-478d-88d9-5eaed28e3944",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # On future runs:\n",
    "# with open(\"raw_knowledge_base.pkl\", \"rb\") as f:\n",
    "#     RAW_KNOWLEDGE_BASE = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1bcac8-cf70-43ef-8933-27efe6b2f755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n\\n\",  # Paragraph breaks\n",
    "    \"\\n\",    # Line breaks\n",
    "    \". \",    # Sentence endings\n",
    "    \"? \",    # Question endings\n",
    "    \"! \",    # Exclamation endings\n",
    "    \" \",     # Fallback to spaces\n",
    "    \"\"       # Catch-all\n",
    "]\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in tqdm(knowledge_base, desc=\"Splitting documents\", unit=\"doc\"):\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        for chunk in chunks:\n",
    "            token_count = len(tokenizer.encode(chunk.page_content))\n",
    "            if token_count > chunk_size:\n",
    "                print(f\"Chunk exceeds limit: {token_count} tokens\\n{chunk.page_content}\\n{'-'*80}\")\n",
    "        docs_processed += chunks\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d11a09-1eab-41c4-86a0-b13cabb9c6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b29c2970c35423881b9aa82b7c3668c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0e5a9dfad6400190a1ec3667697aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ed5e8b5a83408cb9ffafe162f57ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4c8c8d8be84688a8bc6ee3a65f8907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef4e26ecae0484c9250b5a179c54ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Splitting documents:   0%|          | 0/205328 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "docs_processed = split_documents(\n",
    "    256,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5647e4f-d7b3-47e3-a9fe-02a5e9827d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save docs_processed to a file\n",
    "with open(\"docs_processed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs_processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57fd8f5-ba3a-4cf3-a597-48f1b0f34d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load docs_processed from a file\n",
    "with open(\"docs_processed.pkl\", \"rb\") as f:\n",
    "    docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7f7f87-caa7-4ced-adf9-a4f800ec3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e4e565b-1846-41b1-8899-91da28399e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COSINE',\n",
       " 'DOT_PRODUCT',\n",
       " 'EUCLIDEAN_DISTANCE',\n",
       " 'JACCARD',\n",
       " 'MAX_INNER_PRODUCT',\n",
       " '__class__',\n",
       " '__doc__',\n",
       " '__members__',\n",
       " '__module__']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "available_distances = dir(DistanceStrategy)\n",
    "available_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc13212-5721-4a81-9aff-6e02c636620f",
   "metadata": {},
   "source": [
    "## Load the retriever and connect it to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8f49f7-2309-4151-a362-c970f466f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from local\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.load_local(\n",
    "    \"Wikipedia simple/knowledge_vector_database\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf391066-c019-445c-934b-53c816f95067",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"when did the ipod touch 6 gen came out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a74b587-9089-4ccf-bce0-1bd32217d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c73e09-73c7-4d02-97c3-3b0023a888b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================Top document==================================\n",
      "The iPod Touch (6th generation), is the sixth iPod Touch released by Apple Inc. It was first released on July 15, 2015. It is a handheld tablet computer. The iPod Touch 6 can do many things that iPhones can do except it cannot use cellular data (which is required for making calls or texting without WiFi). Critics praise the iPod Touch 6 as a low-cost device that produces good quality photos, though they criticize the iPod Touch 6 for having a poor battery life and a small screen.\n",
      "\n",
      "References\n",
      "\n",
      "Apple hardware\n",
      "==================================Metadata==================================\n",
      "{'id': '665279', 'title': 'IPod Touch (6th generation)', 'url': 'https://simple.wikipedia.org/wiki/IPod%20Touch%20%286th%20generation%29', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(\"\\n==================================Top document==================================\")\n",
    "print(retrieved_docs[i].page_content)\n",
    "print(\"==================================Metadata==================================\")\n",
    "print(retrieved_docs[i].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf73309f-2e00-40d9-a914-1f6ecaa8824f",
   "metadata": {},
   "source": [
    "Connect to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bead79c8-5350-4f8a-9738-1a15e1705c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load the generative model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fa5e72-0e32-4b97-8d26-e545951ccdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Generate answer from query only\n",
    "def generate_baseline_answer(query, model, tokenizer):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_beams=4)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f2ec121-1046-4b68-84d0-30e1211aef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeQAPipeline:\n",
    "    def __init__(self, retriever, model, tokenizer, top_k=3):\n",
    "        \"\"\"\n",
    "        Initialize the generative QA pipeline with retriever, model, tokenizer, and top_k.\n",
    "        \"\"\"\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def generate_answer(self, query):\n",
    "        \"\"\"\n",
    "        Answer a query using the initialized retriever, model, and tokenizer in a generative manner.\n",
    "        \"\"\"\n",
    "        # Retrieve documents\n",
    "        retrieved_docs = self.retriever.similarity_search(query=query, k=self.top_k)\n",
    "        \n",
    "        # Add separators between retrieved documents for better clarity\n",
    "        separator = \"\\n---\\n\"  # Separator between documents\n",
    "        context = separator.join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "        # Prepare the input for the generative model\n",
    "        input_text = f\"With this context: {context} answer the query: {query}\"\n",
    "        \n",
    "        # Tokenize and generate answer\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        outputs = self.model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        # Decode the generated answer\n",
    "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "        return answer, context\n",
    "RAG = GenerativeQAPipeline(KNOWLEDGE_VECTOR_DATABASE,model,tokenizer,top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c3c7b-250d-4d16-a3bd-2ae3e9c25c2e",
   "metadata": {},
   "source": [
    "Now we load a Natural Question dataset to ask questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da35c3ca-06ef-454d-a943-7e5dcfb8e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"google-research-datasets/nq_open\",split = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a04cdc84-4768-4c28-b99b-fa16adb7f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is under the mask of darth vader\n",
      "['Anakin Skywalker']\n"
     ]
    }
   ],
   "source": [
    "i = 17\n",
    "print(ds['question'][i])\n",
    "print(ds['answer'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cd5074e-1967-4715-bc07-d54ff92e4e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who is under the mask of darth vader'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_baseline_answer(ds['question'][i], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6237295e-6bc1-47e7-8b3e-88423d1e0979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anakin Skywalker \n",
      "\n",
      "Darth Vader is a fictional main protagonist character from the Star Wars universe. He appears are The Ed Sullivan Show, Sam and Friends, Play School, Saturday Night Live, Star Wars and Metro Mayor League. Vader is the main character of the Dark Side of the Star Wars series. He appears as a 2 meter-tall man dressed in black armor and a cape. His face is covered with a mask, which has a helmet on top to hide the terrible third degree burns and scars on his face. He has borderline personality disorder.\n",
      "---\n",
      "Government Guy: The tyrannical ruler of Edge City in the future. He wore the mask of the 23rd century, while a time-traveling Stanley wore the mask he brought with him from the 20th century, thus allowing two people to wear the mask at the same time without the Mask being split in two. He is a parody of Ross Perot. Government Guy wore the mask in Future Mask, which was also his only appearance (note the Mask in the future is green due to radiation exposure). Despite wearing the mask he is defeated quite easily by The Mask due to his lack of understanding of the powers it grants.\n",
      "\n",
      "Ace Ventura: Near the end of the two-part crossover \"The Aceman Cometh\"/\"Have Mask, Will Travel\". In fact, the mask hits Ace's rear end, turning it into a head of its own (exactly like Ace's, but colored in a green hue) - possibly ironizing his gag of making his butt \"talk\" (as in the \"ass a few questions\" joke from the original movie).\n",
      "\n",
      "Episode list\n",
      "---\n",
      "Cultural Impact \n",
      "Darth Vader is one of Star Wars' most iconic characters and regarded as the world's most well-known fictional hero. Highly ranked in popularity poll, Darth Vader is the image of good, hatred who kills every one and thing he hates, rage and darkness but also a representation of redemption. He is well known by his black armor, cape, helmet, and particularly his raspy breath due to breathing problems received during a battle with his old master Obi-Wan Kenobi and deep, low-pitched voice from the mask, which often used in different medias as a reference to him.\n",
      "\n",
      "References\n",
      "\n",
      "Other websites\n",
      "\n",
      " Darth Vader official site at StarWars.com\n",
      " Anakin Skywalker official site at StarWars.com\n",
      " Anakin Skywalker / Darth Vader on Wookieepedia, a Star Wars wiki\n",
      " Darth Vader on Encyclopædia Britannica\n",
      "\n",
      "Borderline personality disorder in fiction\n",
      "Fictional people with personality disorders\n",
      "Soulcalibur series guest characters\n",
      "Star Wars Anthology characters\n",
      "Star Wars Skywalker Saga characters\n"
     ]
    }
   ],
   "source": [
    "answer,context = RAG.generate_answer(ds['question'][i])\n",
    "print(answer,'\\n')\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa143bd-7f08-4382-adc6-6c40b4c28206",
   "metadata": {},
   "source": [
    "In this experiment, it increases the performance of the baseline model, when the info is found in the simplified version of the wikipedia that the model has access to (or when it can retrieve it correctly). We will perform another experiment with questions from where we will know that the answer is available inside the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5aeec-ab9a-44ea-a8e2-d9cf32b27143",
   "metadata": {},
   "source": [
    "# Experiment using context-answer questions vs fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104b797-d1c1-4b9e-b620-22d052c4fe7b",
   "metadata": {},
   "source": [
    "Our goal is to experiment if it is necessary a retrain and a dataset with paired context-answer, or if it is enough with RAG (compare accuracy). In case we get something similar, it will mean that the expensive process of creating a dataset with paired context-answer and then fine-tuning a model is not necessary, one just has to add documents with the desired information in the document database, which is really much more desirable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06114d95-4a5c-4b88-9133-03dcaccb6c0c",
   "metadata": {},
   "source": [
    "We will do it with 2 different datasets, a concrete specific-domain (BioASQ) and a general domain. My prediction is that the model will work worse and need the fine-tuning with specific-domain vocabulary, and maybe work better with general questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176a7e5-92b1-416e-bf79-526d854093f6",
   "metadata": {},
   "source": [
    "## First, BioASQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18a69f3-491c-438c-8e70-1ba61795e4bf",
   "metadata": {},
   "source": [
    "### First we create the vector database for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f82cb8e-acd1-43fb-b669-dbd8693fa2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"kroshan/BioASQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6df6e2-442e-472d-833e-062ed9cb32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_validation = ds['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27d76bc-f786-46f0-81a5-4835b6458622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<answer> Bazex syndrome <context> Acrokeratosis paraneoplastica (Bazex syndrome): report of a case associated with small cell lung carcinoma and review of the literature. Acrokeratosis paraneoplastic (Bazex syndrome) is a rare, but distinctive paraneoplastic dermatosis characterized by erythematosquamous lesions located at the acral sites and is most commonly associated with carcinomas of the upper aerodigestive tract. We report a 58-year-old female with a history of a pigmented rash on her extremities, thick keratotic plaques on her hands, and brittle nails. Chest imaging revealed a right upper lobe mass that was proven to be small cell lung carcinoma. While Bazex syndrome has been described in the dermatology literature, it is also important for the radiologist to be aware of this entity and its common presentations.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c970a6-2ab6-4fad-89d9-81c94ad0a82b",
   "metadata": {},
   "source": [
    "We create a vector knowledge database with the context of the validation questions. (we could also add the train context in order to add unneeded context and see if the performance changes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b769cb-09a3-4522-bf68-81dee952d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "answer_pattern = r\"<answer>\\s*(.*?)\\s*<context>\"\n",
    "# Extract the '<context>' part using a regex\n",
    "context_pattern = r\"<context>(.*?)$\"\n",
    "# Add the contexts as a new column to the dataset\n",
    "ds_validation = ds_validation.map(lambda example: {\"context\": re.search(context_pattern, example['text']).group(1).strip()})\n",
    "ds_validation = ds_validation.map(lambda example: {\"answer\": re.search(answer_pattern, example['text']).group(1).strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02ff3d77-b3d9-4ca0-823f-06cab274bd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name synonym of Acrokeratosis paraneoplastica.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658f2461-13b3-4e01-be48-0acdd763680c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bazex syndrome'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16b870c-7fe1-4f7b-b28a-bfbc34db971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Acrokeratosis paraneoplastica (Bazex syndrome): report of a case associated with small cell lung carcinoma and review of the literature. Acrokeratosis paraneoplastic (Bazex syndrome) is a rare, but distinctive paraneoplastic dermatosis characterized by erythematosquamous lesions located at the acral sites and is most commonly associated with carcinomas of the upper aerodigestive tract. We report a 58-year-old female with a history of a pigmented rash on her extremities, thick keratotic plaques on her hands, and brittle nails. Chest imaging revealed a right upper lobe mass that was proven to be small cell lung carcinoma. While Bazex syndrome has been described in the dermatology literature, it is also important for the radiologist to be aware of this entity and its common presentations.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_validation['context'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa9a9fc6-8607-40d0-90a2-f4cac395e92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "487\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(np.unique(ds_validation['question'])))\n",
    "print(len(np.unique(ds_validation['answer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0767fa51-23f9-4ebe-a0df-355d8f577c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize question and answer columns\n",
    "ds_validation = ds_validation.map(\n",
    "    lambda x: {\n",
    "        \"question\": x[\"question\"].lower(),\n",
    "        \"answer\": x[\"answer\"].lower()\n",
    "    },\n",
    "    batched=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd3019f-19ce-44f1-9195-430a94d3d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "378\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(len(np.unique(ds_validation['question'])))\n",
    "print(len(np.unique(ds_validation['answer'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60405527-431d-4a63-8a2d-02f189b2a642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: do the sleeping beauty or the piggybac transposons have higher transposition efficiency?\n",
      "Answers: ['piggybac', 'bac exhi']\n",
      "\n",
      "Question: for which type of diabetes can empagliflozin be used?\n",
      "Answers: ['type 2 diabetes mellitus', '2 diabetes mellitus. int', '(sglt2) inhibitor, is a']\n",
      "\n",
      "Question: from which tissue was the nci-h520 cell-line derived?\n",
      "Answers: ['squamous cell carcinoma', 'non-small cell lung cancer', 'lung']\n",
      "\n",
      "Question: idarucizumab is an antidote of which drug?\n",
      "Answers: ['dabigatran', 'dabigatra', 'for non-v']\n",
      "\n",
      "Question: pridopidine has been tested for treatment of which disorder?\n",
      "Answers: ['huntington disease', 'h huntington disea']\n",
      "\n",
      "Question: rts s as01 vaccine was developed to prevent which disease?\n",
      "Answers: ['malaria', 'malari']\n",
      "\n",
      "Question: simpson grading is used to describe resection of which brain tumor?\n",
      "Answers: ['meningioma', 'meningiom', 'k meningio']\n",
      "\n",
      "Question: the drug jtv519 is derivative of which group of chemical compounds?\n",
      "Answers: ['1,4-benzothiazepine', 'benzothiazepine']\n",
      "\n",
      "Question: the small molecule sea0400 is an inhibitor of which ion antiporter/exchanger?\n",
      "Answers: ['na(+)/ca(2+) exchanger', 'ncx']\n",
      "\n",
      "Question: what disease is small bowel lymphoma commonly associated with\n",
      "Answers: ['celiac disease', 'celiac spru']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Convert dataset to a DataFrame for easier manipulation\n",
    "data = {\"question\": ds_validation[\"question\"], \"answer\": ds_validation[\"answer\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group by question and collect unique answers for each\n",
    "duplicates = defaultdict(list)\n",
    "for question, group in df.groupby(\"question\"):\n",
    "    unique_answers = group[\"answer\"].unique()\n",
    "    if len(unique_answers) > 1:\n",
    "        duplicates[question] = unique_answers\n",
    "\n",
    "# Display examples of duplicate questions with different answers\n",
    "for question, answers in list(duplicates.items())[:10]:  # Display the first 5\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answers: {list(answers)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1d459-a387-4ff3-bbb0-37fc1bdc0583",
   "metadata": {},
   "source": [
    "Let's preprocess the whole list of questions and answers, manually choosing the answers for questions with more than 1 answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28f21dee-6dd7-42ce-96fb-b4fd114436f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc40a4fbd76442d8cda5aa3ae1caebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "\n",
    "    )\n",
    "    for doc in tqdm(ds_validation)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd270688-c8e4-40fc-826a-66829570e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n\\n\",  # Paragraph breaks\n",
    "    \"\\n\",    # Line breaks\n",
    "    \". \",    # Sentence endings\n",
    "    \"? \",    # Question endings\n",
    "    \"! \",    # Exclamation endings\n",
    "    \" \",     # Fallback to spaces\n",
    "    \"\"       # Catch-all\n",
    "]\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        tokenizer,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in tqdm(knowledge_base, desc=\"Splitting documents\", unit=\"doc\"):\n",
    "        chunks = text_splitter.split_documents([doc])\n",
    "        for chunk in chunks:\n",
    "            token_count = len(tokenizer.encode(chunk.page_content))\n",
    "            if token_count > chunk_size:\n",
    "                print(f\"Chunk exceeds limit: {token_count} tokens\\n{chunk.page_content}\\n{'-'*80}\")\n",
    "        docs_processed += chunks\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cec84ecf-942c-4c6e-93bd-a775e6ed0736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4d36effef84b81a0977b2161db019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Splitting documents:   0%|          | 0/4950 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_processed = split_documents(\n",
    "    256,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29286789-2fbc-498b-89eb-176b7f50cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4038"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8193b32f-b681-40f9-bf4f-06cdc075460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6206fd9-c36b-4459-a3a9-a367f710316f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name synonym of acrokeratosis paraneoplastica.\n"
     ]
    }
   ],
   "source": [
    "print(ds_validation['question'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68a14a90-0857-40b1-94ec-e6ca3044727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = ds_validation['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6290f73-d562-4d80-b327-49175d698df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "deaf82bc-ad9c-4386-b7a4-01d001776154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================Top document==================================\n",
      "Acrokeratosis paraneoplastica: Bazex syndrome. Bazex syndrome, or acrokeratosis paraneoplastica, is a cutaneous paraneoplastic syndrome characterized by psoriasiform lesions associated with, usually, a squamous cell carcinoma of the upper aerodigestive tract. We present a case of Bazex syndrome associated with metastatic cervical squamous cell carcinoma with an unknown primary. The features of the condition are discussed in the light of current knowledge.\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(\"\\n==================================Top document==================================\")\n",
    "print(retrieved_docs[i].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206c788-5d4b-467f-bb1c-0fc456c7a85a",
   "metadata": {},
   "source": [
    "### Now connect it to an LLM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61ad5d6-5074-48ac-bed4-d1f806c96d8f",
   "metadata": {},
   "source": [
    "Let's try FLAN-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0960dc9e-9cd4-443c-a6a6-d7da1bbd2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load the generative model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d813ef85-37c5-4d9c-82f3-c4c035f5dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Generate answer from query only\n",
    "def generate_baseline_answer(query, model, tokenizer):\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=50, num_beams=4)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32632314-2253-44bf-9388-27f7fa205ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adenosine triphosphatase (ATPase)'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_baseline_answer(ds_validation['question'][100],model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cd42bd3-ba25-463e-94c2-d70441c8ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeQAPipeline:\n",
    "    def __init__(self, retriever, model, tokenizer, top_k=3):\n",
    "        \"\"\"\n",
    "        Initialize the generative QA pipeline with retriever, model, tokenizer, and top_k.\n",
    "        \"\"\"\n",
    "        self.retriever = retriever\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def generate_answer(self, query):\n",
    "        \"\"\"\n",
    "        Answer a query using the initialized retriever, model, and tokenizer in a generative manner.\n",
    "        \"\"\"\n",
    "        # Retrieve documents\n",
    "        retrieved_docs = self.retriever.similarity_search(query=query, k=self.top_k)\n",
    "        \n",
    "        # Add separators between retrieved documents for better clarity\n",
    "        separator = \"\\n---\\n\"  # Separator between documents\n",
    "        context = separator.join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "        # Prepare the input for the generative model\n",
    "        input_text = f\"With this context: {context} answer the query: {query}\"\n",
    "        \n",
    "        # Tokenize and generate answer\n",
    "        inputs = self.tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        outputs = self.model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        # Decode the generated answer\n",
    "        answer = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "        return answer, context\n",
    "RAG3 = GenerativeQAPipeline(KNOWLEDGE_VECTOR_DATABASE,model,tokenizer,top_k=3)\n",
    "RAG1 = GenerativeQAPipeline(KNOWLEDGE_VECTOR_DATABASE,model,tokenizer,top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "930070ba-716d-4239-9348-79d811da0563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name synonym of acrokeratosis paraneoplastica.\n",
      "bazex syndrome\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Bazex syndrome',\n",
       " 'Acrokeratosis paraneoplastica: Bazex syndrome. Bazex syndrome, or acrokeratosis paraneoplastica, is a cutaneous paraneoplastic syndrome characterized by psoriasiform lesions associated with, usually, a squamous cell carcinoma of the upper aerodigestive tract. We present a case of Bazex syndrome associated with metastatic cervical squamous cell carcinoma with an unknown primary. The features of the condition are discussed in the light of current knowledge.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds_validation['question'][0])\n",
    "print(ds_validation['answer'][0])\n",
    "RAG1.generate_answer(ds_validation['question'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82a40ab4-9932-4ef2-9cfe-a042d01596e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = np.unique(ds_validation['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ff8e055-408a-4e4a-94c5-78f8684c3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does dasatinib promote or inhibit t-cell proliferation?\n",
      "['inhibits']\n"
     ]
    }
   ],
   "source": [
    "i = 8\n",
    "print(questions[i])\n",
    "\n",
    "# Iterate through ds_validation and match the question\n",
    "filtered_answers = [\n",
    "    entry['answer'] for entry in ds_validation\n",
    "    if entry['question'] == questions[i]\n",
    "]\n",
    "print(np.unique(filtered_answers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "286a8c2e-9d1b-48db-ac50-15519d6ea6b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'promote or inhibit t-cell proliferation'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_baseline_answer(questions[i], model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd8b1d76-38f2-47ca-8fcb-f0646c24ae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inhibit \n",
      "\n",
      "Dasatinib inhibits the proliferation and function of CD4+CD25+ regulatory T cells. CD4+CD25+ regulatory T cells (Tregs) can influence various immune responses. Little is known about the effects of the Abl/Src kinase inhibitor dasatinib on Tregs which regulate anti-tumor/leukaemia immune responses. The present study demonstrated that dasatinib inhibited proliferation of Tregs and CD4+CD25- T cells in a dose-dependent manner, which was associated with the decreased production of corresponding cytokines. Treatment of Tregs with dasatinib inhibited the suppressive capacity of Tregs. The mechanisms of this inhibition included arrest of cells in the G0/G1 phase of cell cycle, down-regulation of the transcription factor forkhead box P3, glucocorticoid-induced tumour necrosis factor receptor and the cytotoxic T lymphocyte associated protein 4 as well as inhibition of signaling events through Src and nuclear factor kappaB\n"
     ]
    }
   ],
   "source": [
    "answer,context = RAG1.generate_answer(questions[i])\n",
    "print(answer,'\\n')\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb7fbd88-cae5-42cb-8bcd-97dad72e9933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inhibit \n",
      "\n",
      "Dasatinib inhibits the proliferation and function of CD4+CD25+ regulatory T cells. CD4+CD25+ regulatory T cells (Tregs) can influence various immune responses. Little is known about the effects of the Abl/Src kinase inhibitor dasatinib on Tregs which regulate anti-tumor/leukaemia immune responses. The present study demonstrated that dasatinib inhibited proliferation of Tregs and CD4+CD25- T cells in a dose-dependent manner, which was associated with the decreased production of corresponding cytokines. Treatment of Tregs with dasatinib inhibited the suppressive capacity of Tregs. The mechanisms of this inhibition included arrest of cells in the G0/G1 phase of cell cycle, down-regulation of the transcription factor forkhead box P3, glucocorticoid-induced tumour necrosis factor receptor and the cytotoxic T lymphocyte associated protein 4 as well as inhibition of signaling events through Src and nuclear factor kappaB\n",
      "---\n",
      ". Dasatinib showed an inhibitory effect on the proliferation and function of both Tregs and CD4+CD25- T cells at therapeutically relevant concentrations of the drug. Clinical administration of dasatinib might influence not only the graft-versus-leukaemia effect but also the graft-versus-host-disease in patients receiving dasatinib after allogeneic stem cell transplantation and/or donor lymphocytes infusion as the function of both Tregs and effector T cells are hampered in a similar way by dasatinib.\n",
      "---\n",
      "Dasatinib, a small-molecule protein tyrosine kinase inhibitor, inhibits T-cell activation and proliferation. Dasatinib is an oral small molecule inhibitor of Abl and Src family tyrosine kinases (SFK), including p56(Lck) (Lck). Given the central importance of Lck in transmitting signals from the T-cell receptor (TCR) signaling complex and the potent ability of dasatinib to inhibit Lck activity, we hypothesized this agent could provide a novel route of immunomodulation via targeted inhibition of antigen-induced signaling. Herein, we show that dasatinib inhibits TCR-mediated signal transduction, cellular proliferation, cytokine production, and in vivo T-cell responses. However, dasatinib-mediated inhibition does not induce apoptosis because the effect is reversible or may be overcome by signals bypassing the TCR, such as phorbol ester. Signal transduction and proliferative responses via IL-2 remain essentially unperturbed, suggesting that dasatinib displays specificity for TCR signaling\n"
     ]
    }
   ],
   "source": [
    "answer,context = RAG3.generate_answer(questions[i])\n",
    "print(answer,'\\n')\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf40f83-6683-4ad6-ac40-dd0c750f3113",
   "metadata": {},
   "source": [
    "Another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b278b3d-de62-4104-8456-0c73d01b482c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def answer_question_with_bert(query, retriever, model, tokenizer, top_k=3):\n",
    "#     # Retrieve documents\n",
    "#     retrieved_docs = retriever.similarity_search(query=query, k=top_k)\n",
    "    \n",
    "#     # Initialize variables to store the best answer\n",
    "#     best_answer = None\n",
    "#     best_score = float(\"-inf\")\n",
    "    \n",
    "#     # Iterate over retrieved documents\n",
    "#     for doc in retrieved_docs:\n",
    "#         context = doc.page_content  # Get the document content\n",
    "\n",
    "#         # Tokenize question and context\n",
    "#         inputs = tokenizer(\n",
    "#             query, context, return_tensors=\"pt\", truncation=True, padding=True, max_length=512\n",
    "#         )\n",
    "#         input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "#         # Run the model to get start and end logits\n",
    "#         outputs = model(**inputs)\n",
    "#         start_logits = outputs.start_logits\n",
    "#         end_logits = outputs.end_logits\n",
    "\n",
    "#         # Find the answer span with the highest score\n",
    "#         start_idx = start_logits.argmax()\n",
    "#         end_idx = end_logits.argmax()\n",
    "\n",
    "#         # Decode the answer tokens\n",
    "#         answer = tokenizer.decode(input_ids[start_idx:end_idx + 1])\n",
    "\n",
    "#         # Calculate confidence score (sum of start and end logits)\n",
    "#         score = start_logits[0][start_idx].item() + end_logits[0][end_idx].item()\n",
    "\n",
    "#         # Update the best answer if this score is higher\n",
    "#         if score > best_score:\n",
    "#             best_answer = answer\n",
    "#             best_score = score\n",
    "\n",
    "#     return best_answer, best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73f6e925-d5a3-490e-afc3-3ae6fb7ee180",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which fusion protein is involved in the development of ewing sarcoma?\n",
      "ews/fli1\n"
     ]
    }
   ],
   "source": [
    "print(ds_validation['question'][100])\n",
    "print(ds_validation['answer'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3be0b-e8aa-4022-9032-4bd4fc2e471f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "user_query = ds_validation['question'][100]\n",
    "answer, confidence = answer_question_with_bert(\n",
    "    query=user_query,\n",
    "    retriever=KNOWLEDGE_VECTOR_DATABASE,\n",
    "    model=bert_model,\n",
    "    tokenizer=bert_tokenizer,\n",
    "    top_k=1\n",
    ")\n",
    "\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Confidence: {confidence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
