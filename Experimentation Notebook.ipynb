{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee85def-595b-47bc-a2fb-aea034ad124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datasets import Dataset,load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.schema import Document\n",
    "from functions import CustomHuggingFaceEmbeddings, GenerativePipeline, tokenize_compare, RAGPipeline, split_documents, evaluate_vector_databases, evaluate_answers, RAGPipeline_with_rerank\n",
    "import faiss\n",
    "def embedding_function(text):\n",
    "    return embedding_model_1.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88bb4977-d3cc-4d97-af2f-ef7182681a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag to choose between generating all answers and databases or load them from the disk\n",
    "Generating = True\n",
    "#In case of generating them, flag to choose between saving them on the disk or not.\n",
    "Saving = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c68a34-ed06-41c5-87ee-5f185aa355fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"PKL files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44119407-c989-49cd-bf54-f24f39279982",
   "metadata": {},
   "source": [
    "# First experiment. Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17904c2-db3b-40f4-8b0c-27f432b09b2c",
   "metadata": {},
   "source": [
    "First we use the SQuAD dataset, which contains paired question-context data. We will use its validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2b502a-4a96-49bc-802f-665ae59598c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset = dataset['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e76c72c-241b-4e9a-be56-b77e58b3ca8a",
   "metadata": {},
   "source": [
    "We will not split the documents, as they are already short context documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f484e1-e1cd-403b-b365-8d7da78fab51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f8911a-2ff6-4f77-b189-d22b135be012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade03575d86c4f57a11873448437174b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70868961-b258-4ec8-a182-43ef30a16d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cc888a333a4613ab3244b7a1fc0731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content) \n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb784be7-da7c-4c25-a171-f8f2a316b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2067"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a2a99-5b61-4053-8883-3275949c7a56",
   "metadata": {},
   "source": [
    "As there is only 2067 unique contexts, I will extract a question randomly for each context, and examine which vector database gets better result with the different similarity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118b71e0-c06b-4ca9-885d-2fbf07c196e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [doc.metadata['id'] for doc in docs_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd108176-dce6-464a-9034-4e683ea67e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6465f647-ee12-4335-9960-c19f03df492f",
   "metadata": {},
   "source": [
    "Once converted to LangChain documents, just embed them into a vector database with different similarity metrics. The first model used will be NoInstruct small Embedding v0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91d9fb09-743f-493a-8440-2ce1e93a9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3ceb249-7301-4dec-b20d-a4c8e3c93565",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_1.pkl', 'rb') as f:\n",
    "        VDB_l2_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7397b057-a20d-40c5-8e1c-7684e3bd2902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_1.pkl', 'rb') as f:\n",
    "        VDB_dot_product_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6e6dd5-9bec-47ab-b6dd-c6f23fde7724",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_1.pkl', 'rb') as f:\n",
    "        VDB_cosine_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0744c6c0-fc52-41b9-8d8c-4398a70c7f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [22:26<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_1</th>\n",
       "      <td>0.721335</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.876149</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.981616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_1       0.721335  0.830189  0.876149  0.923077  0.959361  0.981616\n",
       "VDB_dot_product_1  0.721335  0.830189  0.876149  0.923077  0.959361  0.981616\n",
       "VDB_l2_1           0.721335  0.830189  0.876149  0.923077  0.959361  0.981616"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "vector_databases = {\n",
    "    \"VDB_cosine_1\": VDB_cosine_1,\n",
    "    \"VDB_l2_1\": VDB_l2_1,\n",
    "    \"VDB_dot_product_1\": VDB_dot_product_1,\n",
    "}\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table1 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  \n",
    "    .unstack()\n",
    ")\n",
    "pivot_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cab203-59b6-42a8-8c0f-5925b41f2206",
   "metadata": {},
   "source": [
    "Repeat for different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcf73204-744c-49cd-bc7a-5174249af282",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME2 = \"mavihsrr/bge-small-retail-finetuned\"\n",
    "embedding_model_2 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9435a9-164f-41ab-be6d-88d1b1d72b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_2 = FAISS.from_documents(docs_processed, embedding_model_2,distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_2.pkl', 'rb') as f:\n",
    "        VDB_l2_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7befd66-cde5-4f6e-a55b-554fcf910217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_2 = FAISS.from_documents(docs_processed, embedding_model_2, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_2.pkl', 'rb') as f:\n",
    "        VDB_dot_product_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "428f3c3b-346d-4eb8-9101-c262e9203a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_2 = FAISS.from_documents(docs_processed, embedding_model_2, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_2.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_2, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_2.pkl', 'rb') as f:\n",
    "        VDB_cosine_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "959af461-558d-4b4b-953e-957bd0ae80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [20:47<00:00,  1.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_2</th>\n",
       "      <td>0.728592</td>\n",
       "      <td>0.828737</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.920174</td>\n",
       "      <td>0.955007</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_2       0.728592  0.828737  0.874214  0.920174  0.955007  0.981132\n",
       "VDB_dot_product_2  0.728592  0.828737  0.874214  0.920174  0.955007  0.981132\n",
       "VDB_l2_2           0.728592  0.828737  0.874214  0.920174  0.955007  0.981132"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_databases = {\n",
    "    \"VDB_cosine_2\": VDB_cosine_2,\n",
    "    \"VDB_l2_2\": VDB_l2_2,\n",
    "    \"VDB_dot_product_2\": VDB_dot_product_2,\n",
    "}\n",
    "\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table2 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()  \n",
    "    .unstack()\n",
    ")\n",
    "pivot_table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb7f59d3-895e-48a9-9431-86ff3572279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at Snowflake/snowflake-arctic-embed-s and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME3 = \"Snowflake/snowflake-arctic-embed-s\"\n",
    "embedding_model_3 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0057dd-0bbc-4167-99ae-252af0bc879d",
   "metadata": {},
   "source": [
    "Not initialized wieghts shouldn't be used for our task, so ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b090bf-3fd3-48ca-a080-f4204a97d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_3 = FAISS.from_documents(docs_processed, embedding_model_3,distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_3.pkl', 'rb') as f:\n",
    "        VDB_l2_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fdc8c36-e446-4f8e-90d8-d5262ef62955",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_dot_product_3 = FAISS.from_documents(docs_processed, embedding_model_3, distance_strategy = DistanceStrategy.DOT_PRODUCT)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_dot_product_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_dot_product_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_dot_product_3.pkl', 'rb') as f:\n",
    "        VDB_dot_product_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c1a159f-d58c-45e0-8348-0ff01dfc642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_cosine_3 = FAISS.from_documents(docs_processed, embedding_model_3, distance_strategy=DistanceStrategy.COSINE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_cosine_3.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_cosine_3, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_cosine_3.pkl', 'rb') as f:\n",
    "        VDB_cosine_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a1fd7ed-2b9e-4b1f-bd6d-b1685777321a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating questions: 100%|████████████████████████████████████████████████████████| 2067/2067 [16:41<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>k</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>db_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VDB_cosine_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_dot_product_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VDB_l2_3</th>\n",
       "      <td>0.583938</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.823416</td>\n",
       "      <td>0.893566</td>\n",
       "      <td>0.936139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "k                        1         2         3         5         10        20\n",
       "db_name                                                                      \n",
       "VDB_cosine_3       0.583938  0.707305  0.769231  0.823416  0.893566  0.936139\n",
       "VDB_dot_product_3  0.583938  0.707305  0.769231  0.823416  0.893566  0.936139\n",
       "VDB_l2_3           0.583938  0.707305  0.769231  0.823416  0.893566  0.936139"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_databases = {\n",
    "    \"VDB_cosine_3\": VDB_cosine_3,\n",
    "    \"VDB_l2_3\": VDB_l2_3,\n",
    "    \"VDB_dot_product_3\": VDB_dot_product_3,\n",
    "}\n",
    "\n",
    "\n",
    "k_values = [1, 2, 3, 5, 10, 20]\n",
    "\n",
    "results = evaluate_vector_databases(vector_databases, subset, k_values)\n",
    "results_df = pd.DataFrame(results)\n",
    "pivot_table3 = (\n",
    "    results_df.groupby(['db_name', 'k'])['actual_context_found']\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "pivot_table3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b589d1-9bda-4565-bce7-dab66bf33078",
   "metadata": {},
   "source": [
    "# Second experiment. Baseline, contexted and RAG models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe9f65-35f2-455d-b787-cf8263a46974",
   "metadata": {},
   "source": [
    "Now we will create a RAG pipeline. First, a normal generative pipeline with context, where we test the model without context and with the correct context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db4a39e5-a6d2-4d81-802a-5bce06bed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativePipeline()\n",
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3835a6ab-3076-4acb-9f8b-e64f79a7fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    baseline_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = model.generate_answer(question, context=\"\")  # Empty context\n",
    "        baseline_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths': subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/baseline_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(baseline_answers, f)\n",
    "else:\n",
    "    with open('PKL files/baseline_answers.pkl', 'rb') as f:\n",
    "        baseline_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86df60ee-bcbf-4847-813e-4e470aff0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    contexted_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        context = subset[i]['context']\n",
    "        answer = model.generate_answer(question,context)\n",
    "        contexted_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/contexted_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(contexted_answers, f)\n",
    "else:\n",
    "    with open('PKL files/contexted_answers.pkl', 'rb') as f:\n",
    "        contexted_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4794bbf9-8c65-4bef-8cf9-25ca6dd3bded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8808e0f05014746a4e38de77600c7b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for baseline model:\n",
      "37 / 2067\n",
      "Match Score: 0.0179\n"
     ]
    }
   ],
   "source": [
    "exact_matches,errors = evaluate_answers(baseline_answers,tokenizer,return_errors = True)\n",
    "\n",
    "print('Evaluation score for baseline model:')\n",
    "print(f\"{exact_matches} / 2067\")\n",
    "print(f\"Match Score: {exact_matches / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b38d3191-b45f-4701-900d-aab475652dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3974a13e1033401ab7b687e5c44d9424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match scorefor model with correct context:\n",
      "1438 / 2067\n",
      "Match Score: 0.6957\n"
     ]
    }
   ],
   "source": [
    "exact_matches_2 = evaluate_answers(contexted_answers, tokenizer)\n",
    "\n",
    "print('Match scorefor model with correct context:')\n",
    "print(f\"{exact_matches_2} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_2 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f635d0f-4952-4585-889d-0d99fd443e8c",
   "metadata": {},
   "source": [
    "This is the maximum expected for our generative model. Let's see RAG. We use different embedding model depending on the k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec019bb0-a546-4b10-9ab2-fc22a384981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_2,\n",
    "        retriever_kgt1=VDB_l2_1,\n",
    "        device=\"cpu\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70162077-c5d8-4bcf-a592-b901f5b8a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        rag_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers.pkl', 'rb') as f:\n",
    "        rag_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "545572d7-6d2e-4fbf-8504-9878322ccffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers_2 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        rag_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers_2.pkl', 'rb') as f:\n",
    "        rag_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f760871-c141-468c-a2ad-1044dd80315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rag_answers_3 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        rag_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rag_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(rag_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/rag_answers_3.pkl', 'rb') as f:\n",
    "        rag_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02b1693c-3ce8-4ecc-a812-8e6192c84fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7588c9bc97442bb19c5af748777c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "1082 / 2067\n",
      "Match Score: 0.5235\n"
     ]
    }
   ],
   "source": [
    "exact_matches_3 = evaluate_answers(rag_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_3} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_3 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdb6d570-9e14-4d06-87bb-dc5edae1ef3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8810e73114604212ab80e4c996b07c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k=2:\n",
      "1165 / 2067\n",
      "Match Score: 0.5636\n"
     ]
    }
   ],
   "source": [
    "exact_matches_4 = evaluate_answers(rag_answers_2,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k=2:')\n",
    "print(f\"{exact_matches_4} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_4 / 2067:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "109ad974-0427-4964-ace7-e02aef59cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474370f7025f4e9d951422ac0189c979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k=3:\n",
      "1163 / 2067\n",
      "Match Score: 0.5627\n"
     ]
    }
   ],
   "source": [
    "exact_matches_5 = evaluate_answers(rag_answers_3,tokenizer)\n",
    "\n",
    "\n",
    "print('Evaluation score for RAG model with k=3:')\n",
    "print(f\"{exact_matches_5} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_5 / 2067:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb55340-a89c-499c-9ba1-f67ae0c8c91d",
   "metadata": {},
   "source": [
    "# Natural questions from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a33d1-5ab9-4dd5-bae7-aad9691ed48d",
   "metadata": {},
   "source": [
    "We will use TriviaQA for additional experiment with different question dataset. We use a subset of 1000 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "822b4696-ba49-4325-94ca-ae7a02701e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e082a9c1-39a4-452e-a594-fbc3d596c449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099da4aa60744982966544b1388d4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\", streaming=True)\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bda410d3-aac4-4323-a4a0-e44bed36b8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which Lloyd Webber musical premiered in the US on 10th December 1993?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset[0]['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdbae74-8cdd-4d15-b454-49b3d49a18b3",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd09991-d883-41e7-9886-cf210816098d",
   "metadata": {},
   "source": [
    "Again, baseline model without contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2357b72-a9bd-466c-b8ef-0e9eb50201e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativePipeline()\n",
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7077ccd-94a0-45ad-9c74-11b2651df084",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    baseline_triviaqa_answers = []\n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = model.generate_answer(question, context=\"\")\n",
    "        baseline_triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths': subset[i][\"answer\"]['aliases']})\n",
    "    if Saving:\n",
    "        with open('PKL files/baseline_triviaqa_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(baseline_triviaqa_answers, f)\n",
    "else:\n",
    "    with open('PKL files/baseline_triviaqa_answers.pkl', 'rb') as f:\n",
    "        baseline_triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acb54c97-19df-4d11-ac05-357985d598e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0897e447d89b429d8deed7bb152d4382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for baseline model:\n",
      "70 / 1000\n",
      "Match Score: 0.0700\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_baseline = evaluate_answers(baseline_triviaqa_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for baseline model:')\n",
    "print(f\"{matches_triviaqa_baseline} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_baseline / 1000:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7739bb-c112-4a9b-b882-5ca2bcea969d",
   "metadata": {},
   "source": [
    "## Extracting actual Contexts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082a631b-f7fa-413a-8332-fb53f96ea619",
   "metadata": {},
   "source": [
    "We extract the wikipedia passages stated as context for each question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdaabb69-4787-4182-85f6-43838e30cbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e7a3a0e14e44ab954d05d325ea317c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1717\n"
     ]
    }
   ],
   "source": [
    "suma = 0\n",
    "for doc in tqdm(subset['entity_pages']):\n",
    "    suma += len(doc[\"wiki_context\"])\n",
    "print(suma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb3d5dcb-ad1b-4ee2-9c80-35e5494ed395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fbb4e8228d4d7c995557057336b593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entity pages:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LangchainDocument objects created (after deduplication): 1537\n"
     ]
    }
   ],
   "source": [
    "Raw_contexts = []\n",
    "\n",
    "unique_contents = set()\n",
    "\n",
    "for entry in tqdm(subset, desc=\"Processing entity pages\"):\n",
    "        entity_pages = entry[\"entity_pages\"]\n",
    "        for i, context in enumerate(entity_pages[\"wiki_context\"]):\n",
    "            if context not in unique_contents:\n",
    "                unique_contents.add(context)\n",
    "                Raw_contexts.append(\n",
    "                    LangchainDocument(\n",
    "                        page_content=context,\n",
    "                        metadata={\n",
    "                            \"title\": entity_pages[\"title\"][i],\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "print(f\"Total LangchainDocument objects created (after deduplication): {len(Raw_contexts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfabfa-622d-41ca-a8b5-4624a854b021",
   "metadata": {},
   "source": [
    "There is a total of 1717 contexts, and when deleting the duplicates there is 1537."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1af08-e4c8-41a5-9a70-2d0066830ebc",
   "metadata": {},
   "source": [
    "Using the embedding model with better performance with higher $k$, as for $k=1$ the performance is practically the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0e8db9c-5460-4a53-a926-fd3c2e1b9d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0688d55-ea24-42ad-938e-694a57364bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Raw_contexts,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "        docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee368ade-43c4-48c3-8a94-87251508f743",
   "metadata": {},
   "source": [
    "Next cell is done by batches and requires saving always. I computes the embeddings of the chunked texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8260e067-5de8-40a9-85b7-481b4a0a1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    output_dir = \"embeddings\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_size = 20000\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue \n",
    "        \n",
    "        end_idx = min(start_idx + batch_size, num_docs)\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            batch_embeddings = []\n",
    "            # Compute embeddings\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e03d0b0-b3d9-4dff-abb2-0b0d733a7b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (111999, 384)\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"embeddings\"\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55c1c6c6-8eba-425d-b60f-35065c42eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "    index.add(embeddings)\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    VDB_l2_contexts = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_contexts.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_contexts, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_contexts.pkl\", \"rb\") as f:\n",
    "        VDB_l2_contexts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380f035-49d7-4d34-bce3-381169103273",
   "metadata": {},
   "source": [
    "We now create the RAG generative pipeline and answer all the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a77f452-f299-4ade-ac85-68d1d6e690df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_contexts,\n",
    "        retriever_kgt1=VDB_l2_contexts,\n",
    "        device=\"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dea5a8ef-bb1f-4850-80cc-e89ffd0b4a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        triviaqa_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers.pkl', 'rb') as f:\n",
    "        triviaqa_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4686b9b-5250-4475-830e-ed3ff5bc0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_2 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        triviaqa_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30a6a64f-ddd4-4e14-96f6-8fc990cb9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_3 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        triviaqa_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e766c10e-ab60-4bfa-a6b7-770af4a6a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_4 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=4,return_context = True)\n",
    "        triviaqa_answers_4.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_4.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_4, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_4.pkl', 'rb') as f:\n",
    "        triviaqa_answers_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3a5a8bd-59f8-4a9d-b2d3-83d5e3fd25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_5 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=5,return_context = True)\n",
    "        triviaqa_answers_5.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_5.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_5, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_5.pkl', 'rb') as f:\n",
    "        triviaqa_answers_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "560095f6-31d9-45f9-bcb9-05480bbff864",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_answers_6 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=6,return_context = True)\n",
    "        triviaqa_answers_6.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_answers_6.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_answers_6, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_answers_6.pkl', 'rb') as f:\n",
    "        triviaqa_answers_6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19822f55-fead-4426-b266-56b211f17018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb459f0623d94f4e8cc794cbfebb5d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "384 / 1000\n",
      "Match Score: 0.3840\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa = evaluate_answers(triviaqa_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{matches_triviaqa} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7fcace7-eee5-41e8-ab12-8099fecf34ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06264b2c7444b31a1c16c6efd85aba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "457 / 1000\n",
      "Match Score: 0.4570\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_2 = evaluate_answers(triviaqa_answers_2,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{matches_triviaqa_2} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7823bcff-f341-47d5-80cd-fa9ae88d8d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2800d42a032847f99b395db59587cdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "476 / 1000\n",
      "Match Score: 0.4760\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_3 = evaluate_answers(triviaqa_answers_3,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{matches_triviaqa_3} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df5d8dac-3db8-4322-b0af-e4305d5724d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d398d4739e946b1976a044663bbe65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 4:\n",
      "487 / 1000\n",
      "Match Score: 0.4870\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_4 = evaluate_answers(triviaqa_answers_4,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 4:')\n",
    "print(f\"{matches_triviaqa_4} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_4 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2faffb1b-fc8d-4aac-b651-c29d98a08a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debe95f3eb874821ad125d02a0e42134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 5:\n",
      "478 / 1000\n",
      "Match Score: 0.4780\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_5 = evaluate_answers(triviaqa_answers_5,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 5:')\n",
    "print(f\"{matches_triviaqa_5} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_5 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f82f936-11a2-45f5-8d35-76f7bee8b425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c3919da00849059a58478081b33dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 6:\n",
      "475 / 1000\n",
      "Match Score: 0.4750\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_6 = evaluate_answers(triviaqa_answers_6,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 6:')\n",
    "print(f\"{matches_triviaqa_6} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_6 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522cc4a-c104-4832-9d11-ae4a0620363d",
   "metadata": {},
   "source": [
    "## Additional wikipedia passages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af15169-3d2c-468d-8f7e-31df992082d0",
   "metadata": {},
   "source": [
    "We add wikipedia passages to go to a more real case, where we have additional information. Preprocess them in the exact same way as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9c5aa64-6bb2-4e35-b8c8-6ee69b1d38a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7bd48893-2d7f-4b17-87a2-ae23f4cdf2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fde620561d74c31a23f65dda9e01f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Additional_documents = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6a69e00-e291-4f2a-b4d8-8d1dbd6742be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed_2 = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Additional_documents,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed_2, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed_2.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed_2, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed_2.pkl\", \"rb\") as f:\n",
    "        docs_processed_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2afe0d66-5ecf-4832-9d57-d691c39554cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    output_dir = \"embeddings_2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_size = 100000\n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue \n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            batch_embeddings = []\n",
    "            # Compute embeddings\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41cb9690-ccbd-46e4-b247-339598d45631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"embeddings_2\"\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings_2 = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings_2.shape}\")\n",
    "embeddings_2 = embeddings_2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bc7b485-1307-42fe-947e-e567b6ad78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "    all_embeddings = np.concatenate([embeddings, embeddings_2]).astype(np.float32)\n",
    "    index.add(all_embeddings)\n",
    "    all_docs = docs_processed + docs_processed_2\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(all_docs)}\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_noisy = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_noisy.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_noisy, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_noisy.pkl\", \"rb\") as f:\n",
    "        VDB_l2_noisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbbcedd-c149-48b4-aa40-16da7a680306",
   "metadata": {},
   "source": [
    "With the vector database retriever set up, again create the RAG pipeline and evaluate all the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "613168c5-baa7-49ab-a8bb-53d89d65c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline = RAGPipeline(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever_k1=VDB_l2_noisy,\n",
    "        retriever_kgt1=VDB_l2_noisy,\n",
    "        device=\"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "364ed139-397a-459e-bd88-3c47dab75d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=1,return_context = True)\n",
    "        triviaqa_noisy_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f44ce7e1-9359-49f0-bddb-754be5128642",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_2 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=2,return_context = True)\n",
    "        triviaqa_noisy_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "834d1289-d2bd-4eea-ad15-1d4de1d8111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_3 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=3,return_context = True)\n",
    "        triviaqa_noisy_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9877518e-4273-48bb-93f4-132d1fd6a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_4 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=4,return_context = True)\n",
    "        triviaqa_noisy_answers_4.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_4.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_4, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_4.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd930428-982b-453a-9bab-b62910eb9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_5 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=5,return_context = True)\n",
    "        triviaqa_noisy_answers_5.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_5.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_5, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_5.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33af9475-9b37-448c-9ef8-38bd5044d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_noisy_answers_6 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline.generate_answer(question,k=6,return_context = True)\n",
    "        triviaqa_noisy_answers_6.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_noisy_answers_6.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_noisy_answers_6, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_noisy_answers_6.pkl', 'rb') as f:\n",
    "        triviaqa_noisy_answers_6 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "faecc053-17c4-4625-af16-4b7b5127f191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41519d9e0f84f1db95d7e6cab874d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "399 / 1000\n",
      "Match Score: 0.3990\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa = evaluate_answers(triviaqa_noisy_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{matches_triviaqa} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "beab4911-256d-4de9-8002-ade0324a28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e3c6fc50d34361aac3de77bb3be07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "463 / 1000\n",
      "Match Score: 0.4630\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_2 = evaluate_answers(triviaqa_noisy_answers_2,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{matches_triviaqa_2} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80eedddf-dfb5-492c-b25b-90368b2c5039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417f0205438a4cb6a07dbf9660a2fd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "487 / 1000\n",
      "Match Score: 0.4870\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_3 = evaluate_answers(triviaqa_noisy_answers_3,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{matches_triviaqa_3} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4875b6a8-3b59-43a9-a44e-dbedf9b3ef9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76335d0218e145fd895483bd612776a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 4:\n",
      "500 / 1000\n",
      "Match Score: 0.5000\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_4 = evaluate_answers(triviaqa_noisy_answers_4,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 4:')\n",
    "print(f\"{matches_triviaqa_4} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_4 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ed0282f-a994-4a9a-b02a-1af9df91a93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f20abba55540ff972d3cff4c955a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 5:\n",
      "496 / 1000\n",
      "Match Score: 0.4960\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_5 = evaluate_answers(triviaqa_noisy_answers_5,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 5:')\n",
    "print(f\"{matches_triviaqa_5} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_5 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d056da6c-ec72-4444-8a58-edde383f7f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2895b99d8a644718905d551a44522838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 6:\n",
      "493 / 1000\n",
      "Match Score: 0.4930\n"
     ]
    }
   ],
   "source": [
    "matches_triviaqa_6 = evaluate_answers(triviaqa_noisy_answers_6,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 6:')\n",
    "print(f\"{matches_triviaqa_6} / 1000\")\n",
    "print(f\"Match Score: {matches_triviaqa_6 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c549ee-95bd-47e2-b5db-bd06b1ef80e3",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d9fa2-8237-406d-9fe0-ee2c8a75668e",
   "metadata": {},
   "source": [
    "We apply re-ranking to both experiments. First to the SQuAD dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898a46f0-fec5-43f6-a2c4-a03ad45d8f81",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f35fd6-a529-41bb-8558-2d2aa06af5da",
   "metadata": {},
   "source": [
    "First evaluate if the context is found between the retrieved documents. Same as first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f61c047d-07a1-4308-abdb-db744ba480b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259fca6572044dbf8e7ee8beb8ce2c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eddecc3d0a749398053db871cd73d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing documents:   0%|          | 0/10570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"squad\")\n",
    "dataset = dataset['validation']\n",
    "Raw_squad = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"context\"],\n",
    "        metadata={\n",
    "            \"id\": doc[\"id\"],\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "unique_content = set()\n",
    "docs_processed = []\n",
    "for doc in tqdm(Raw_squad, desc=\"Processing documents\"):\n",
    "    if doc.page_content not in unique_content:\n",
    "        unique_content.add(doc.page_content)  # Track unique page_content\n",
    "        docs_processed.append(\n",
    "            LangchainDocument(\n",
    "                page_content=doc.page_content,\n",
    "                metadata=doc.metadata\n",
    "            )\n",
    "        )\n",
    "id_list = [doc.metadata['id'] for doc in docs_processed]\n",
    "subset = dataset.filter(lambda row: row['id'] in id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d61c122c-8f66-402e-a49b-c5ddae5d1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1fa6e476-0de3-4216-a537-8a291ec5615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    VDB_l2_1 = FAISS.from_documents(docs_processed, embedding_model_1, distance_strategy = DistanceStrategy.EUCLIDEAN_DISTANCE)\n",
    "    if Saving:\n",
    "        with open('PKL files/VDB_l2_1.pkl', 'wb') as f:\n",
    "            pickle.dump(VDB_l2_1, f)\n",
    "else:\n",
    "    with open('PKL files/VDB_l2_1.pkl', 'rb') as f:\n",
    "        VDB_l2_1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "06f8bf25-031d-463d-ac60-a20701bad3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_1,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdfeaef-ed39-4931-a274-ef692a099b34",
   "metadata": {},
   "source": [
    "We retrieve documents with the first retriever with $k=20$, and re-rank them with different $k_{rerank}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf717f01-7d5a-43fe-90b9-168e4f2a88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    k_values = [1,2,3,4]\n",
    "    rerank_retrieve_results = []\n",
    "    # Iterate through the subset of questions\n",
    "    for row in tqdm(subset, desc=\"Evaluating questions\"):\n",
    "        question_id = row['id']\n",
    "        question_text = row['question']\n",
    "        actual_context = row['context']\n",
    "        # Evaluate for each k value\n",
    "        for k in k_values:\n",
    "            retrieved = rag_pipeline_with_rerank.retrieve_context(question_text,k=20)\n",
    "            retrieved_docs,scores = rag_pipeline_with_rerank.rerank_context(retrieved,k, question_text, return_scores = True)\n",
    "            found = any(doc == actual_context for doc in retrieved_docs)\n",
    "            rerank_retrieve_results.append({\n",
    "                \"question_id\": question_id,\n",
    "                \"question\": question_text,\n",
    "                \"actual_context\": actual_context,\n",
    "                \"k\": k,\n",
    "                \"retrieved_docs\": [doc for doc in retrieved_docs],\n",
    "                \"actual_context_found\": found,\n",
    "                \"scores\": scores,\n",
    "            })\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_retrieve_results.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_retrieve_results, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_retrieve_results.pkl', 'rb') as f:\n",
    "        rerank_retrieve_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cd83eab-4ddb-4492-a11e-5e17a8150ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>times_context_found</th>\n",
       "      <th>total_questions</th>\n",
       "      <th>percentage_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1894</td>\n",
       "      <td>2067</td>\n",
       "      <td>91.630382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>2067</td>\n",
       "      <td>95.839381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>2067</td>\n",
       "      <td>97.194001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "      <td>2067</td>\n",
       "      <td>97.387518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   k  times_context_found  total_questions  percentage_found\n",
       "0  1                 1894             2067         91.630382\n",
       "1  2                 1981             2067         95.839381\n",
       "2  3                 2009             2067         97.194001\n",
       "3  4                 2013             2067         97.387518"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(rerank_retrieve_results)\n",
    "summary_table = df_results.groupby(\"k\").agg(\n",
    "    times_context_found=(\"actual_context_found\", \"sum\"),\n",
    "    total_questions=(\"actual_context_found\", \"count\")\n",
    ").reset_index()\n",
    "summary_table[\"percentage_found\"] = (\n",
    "    summary_table[\"times_context_found\"] / summary_table[\"total_questions\"] * 100\n",
    ")\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae79bb-be0d-48bf-b677-048e2dae496d",
   "metadata": {},
   "source": [
    "Now, we evaluate the RAG pipeline with re-rank on all the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c6eda907-24bb-4de2-b79b-8427adb3968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1)\n",
    "        rerank_answers.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text']})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers.pkl', 'rb') as f:\n",
    "        rerank_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b504ba89-93bf-4c7d-8ed9-6cf8b71e5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers_2 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        rerank_answers_2.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers_2.pkl', 'rb') as f:\n",
    "        rerank_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f4cb27fb-fafa-4513-a67b-8a6540d3339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    rerank_answers_3 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        rerank_answers_3.append({\"id\": subset[i][\"id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answers\"]['text'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/rerank_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(rerank_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/rerank_answers_3.pkl', 'rb') as f:\n",
    "        rerank_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "20263ee2-b228-4229-bcbe-a724426401ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c6521f0-0b51-451f-99f7-d8064e18b524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac295b851c76400d95f6b6073e3b7cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1 and rerank:\n",
      "1334 / 2067\n",
      "Match Score: 0.6454\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank = evaluate_answers(rerank_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 1 and rerank:')\n",
    "print(f\"{exact_matches_rerank} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_rerank / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f14f451-8b02-4c48-97eb-1b6eea416289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdecc7c09b444aff9c97edda62fa3c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2 and rerank:\n",
      "1279 / 2067\n",
      "Match Score: 0.6188\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_2 = evaluate_answers(rerank_answers_2,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 2 and rerank:')\n",
    "print(f\"{exact_matches_rerank_2} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_rerank_2 / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6adcd881-a6df-43da-8c2c-39b46c00e342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5540cafcf5448ea8ca5d037b9f6fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/2067 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3 and rerank:\n",
      "1259 / 2067\n",
      "Match Score: 0.6091\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_3 = evaluate_answers(rerank_answers_3,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 3 and rerank:')\n",
    "print(f\"{exact_matches_rerank_3} / 2067\")\n",
    "print(f\"Match Score: {exact_matches_rerank_3 / 2067:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa14bc-928c-4a55-b17e-6f56342e1901",
   "metadata": {},
   "source": [
    "## With TriviaQA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b558a53-ed33-4f52-bdbf-807ab939aba1",
   "metadata": {},
   "source": [
    "Finally, we do the same for the TriviaQA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5d051-6e1d-44f9-9e2c-d919fd92f10c",
   "metadata": {},
   "source": [
    "### With contexts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae33dd-05c7-4c28-8058-f48cb245cc8d",
   "metadata": {},
   "source": [
    "First, with only its own contexts (repeat the preprocess of the documents so each section can be run individually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5eef28c4-d9eb-4ab0-9c87-3faef10ac783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ccf0f574ae84b4ca243ca51e238bd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamed_dataset = load_dataset(\"trivia_qa\", \"rc.wikipedia\", split=\"validation\", streaming=True)\n",
    "subset_list = [sample for _, sample in zip(range(1000), streamed_dataset)]\n",
    "subset = Dataset.from_dict({key: [entry[key] for entry in subset_list] for key in subset_list[0].keys()})\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "30b241c5-d885-4178-9207-897fc946ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb423f5dfef4a6ca5f79deb2b8145f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing entity pages:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total LangchainDocument objects created (after deduplication): 1537\n"
     ]
    }
   ],
   "source": [
    "Raw_contexts = []\n",
    "\n",
    "unique_contents = set()\n",
    "\n",
    "for entry in tqdm(subset, desc=\"Processing entity pages\"):\n",
    "        entity_pages = entry[\"entity_pages\"]\n",
    "        for i, context in enumerate(entity_pages[\"wiki_context\"]):\n",
    "            if context not in unique_contents:\n",
    "                unique_contents.add(context)\n",
    "                Raw_contexts.append(\n",
    "                    LangchainDocument(\n",
    "                        page_content=context,\n",
    "                        metadata={\n",
    "                            \"title\": entity_pages[\"title\"][i],\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "print(f\"Total LangchainDocument objects created (after deduplication): {len(Raw_contexts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45515659-26c8-4d9e-8670-cfdfc9cfa756",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4376799a-bd20-4e06-9cad-266beb076069",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Raw_contexts,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed.pkl\", \"rb\") as f:\n",
    "        docs_processed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6966786b-b8ec-48e1-8739-aed010f0e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    output_dir = \"embeddings\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_size = 20000\n",
    "    \n",
    "    # Get already processed batches (for resuming)\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs)\n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        try:\n",
    "            batch_embeddings = []\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9ccf0867-f67d-4081-a5d7-1e9c874bf05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (111999, 384)\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"embeddings\"\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings.shape}\")\n",
    "embeddings = embeddings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fac81aef-be45-4fc3-8d6c-6ad93bb719af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)  # Use L2 distance (Euclidean)\n",
    "    index.add(embeddings)\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(docs_processed)}\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_contexts = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_contexts.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_contexts, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_contexts.pkl\", \"rb\") as f:\n",
    "        VDB_l2_contexts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b943029-f5bf-4d7d-b415-a36bbae707eb",
   "metadata": {},
   "source": [
    "Generate the RAG pipeline with re-rank, and answer and evaluate all the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d6c6f7ed-6732-469d-8d48-3ce0e108172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_contexts,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90589c9a-3abc-4b05-b58a-5761b0dde490",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1,return_context = True)\n",
    "        triviaqa_rerank_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "50b28b45-fb07-41fb-ba39-8cf8f30bb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers_2 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        triviaqa_rerank_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "120a1154-8b4c-4e43-9127-add6cf83029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_answers_3 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        triviaqa_rerank_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "271793b6-417c-4b6a-8b55-ddf9a306cf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0ca0a05a-83e9-46d3-9b8b-d8c011ebb1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efb168530a7423a9e7dba22521d2d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "547 / 1000\n",
      "Match Score: 0.5470\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank = evaluate_answers(triviaqa_rerank_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_rerank} / 1000\")\n",
    "print(f\"Match Score: {exact_matches_rerank / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4a9e9f18-2cd5-401e-9013-c348ed6087e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d87358b954480c9e4a3727d4a224ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "554 / 1000\n",
      "Match Score: 0.5540\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_2 = evaluate_answers(triviaqa_rerank_answers_2,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_rerank_2} / 1000\")\n",
    "print(f\"Match Score: {exact_matches_rerank_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c61af53c-9cc1-4481-a7da-6175088cfd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd34d438a5394690967936685b3e8802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "554 / 1000\n",
      "Match Score: 0.5540\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_3 = evaluate_answers(triviaqa_rerank_answers_3,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_rerank_3} / 1000\")\n",
    "print(f\"Match Score: {exact_matches_rerank_3 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97911d71-7bc0-41a0-8b7e-73ae0afa9193",
   "metadata": {},
   "source": [
    "### With Additional contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35f827-7f04-4539-8a10-92ef9ed3319a",
   "metadata": {},
   "source": [
    "Finally, we repeat adding the additional contexts. Again, repeat the preprocess of documents so each section can be run independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2e78fc65-93ec-4a43-a96f-3bb8cbbc8ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'url', 'title', 'text'],\n",
       "    num_rows: 205328\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"wikipedia\",\n",
    "    \"20220301.simple\",\n",
    "    split=\"train\",\n",
    "    trust_remote_code=True, \n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a977cf2a-67b1-4146-a0e9-b873f0543772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2960267939ef4bb0aea0e91a871fdcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/205328 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Additional_documents = [\n",
    "    LangchainDocument(\n",
    "        page_content=doc[\"text\"],\n",
    "        metadata={\n",
    "            \"title\": doc[\"title\"]\n",
    "        }\n",
    "    )\n",
    "    for doc in tqdm(dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "18cf956c-3eb6-4e55-9cf5-885d47838deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME1 = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model_1 = CustomHuggingFaceEmbeddings(EMBEDDING_MODEL_NAME1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7050927-f78e-4a7b-b0c2-010a10de53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    docs_processed_2 = split_documents(\n",
    "    128,  # We choose a chunk size adapted to our model\n",
    "    Additional_documents,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME1,\n",
    "    )\n",
    "    for doc in tqdm(docs_processed_2, desc=\"Adding titles to chunks\"):\n",
    "        title = doc.metadata[\"title\"]\n",
    "        doc.page_content = f\"{title}\\n\\n{doc.page_content}\"\n",
    "    if Saving:\n",
    "        with open(\"PKL files/docs_processed_2.pkl\", \"wb\") as f:\n",
    "            pickle.dump(docs_processed_2, f)\n",
    "else:\n",
    "    with open(\"PKL files/docs_processed_2.pkl\", \"rb\") as f:\n",
    "        docs_processed_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eb4e9406-8304-492a-8bc6-7d56da4fcf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    output_dir = \"embeddings_2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    batch_size = 100000\n",
    "    processed_batches = {\n",
    "        int(f.split('_')[-1].split('.')[0]) for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\")\n",
    "    }\n",
    "    \n",
    "    # Process documents in batches\n",
    "    num_docs = len(docs_processed)\n",
    "    for start_idx in range(0, num_docs, batch_size):\n",
    "        batch_number = start_idx // batch_size\n",
    "        if batch_number in processed_batches:\n",
    "            continue\n",
    "        \n",
    "        # Define end index for the current batch\n",
    "        end_idx = min(start_idx + batch_size, num_docs) \n",
    "        batch_docs = docs_processed[start_idx:end_idx]\n",
    "        \n",
    "        try:\n",
    "            batch_embeddings = []\n",
    "            for doc in tqdm(batch_docs, desc=f\"Processing batch {batch_number}\", unit=\"doc\"):\n",
    "                batch_embeddings.append(embedding_model_1.embed_query(doc.page_content))\n",
    "            batch_embeddings = np.array(batch_embeddings)\n",
    "            batch_file = os.path.join(output_dir, f\"embeddings_batch_{batch_number}.npy\")\n",
    "            np.save(batch_file, batch_embeddings)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch {batch_number}: {e}\")\n",
    "            # Save progress in case of an error\n",
    "            with open(os.path.join(output_dir, \"error_log.txt\"), \"a\") as log_file:\n",
    "                log_file.write(f\"Batch {batch_number} failed at index range {start_idx}-{end_idx}: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3c153ea8-f662-4a3a-aa50-d5efe5bbb9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recovered embeddings shape: (656282, 384)\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"embeddings_2\"\n",
    "batch_files = sorted(\n",
    "    [f for f in os.listdir(output_dir) if f.startswith(\"embeddings_batch_\") and f.endswith(\".npy\")],\n",
    "    key=lambda x: int(x.split('_')[-1].split('.')[0])\n",
    ")\n",
    "# Load and concatenate all embeddings\n",
    "embeddings_2 = np.vstack([np.load(os.path.join(output_dir, f)) for f in batch_files])\n",
    "\n",
    "print(f\"Recovered embeddings shape: {embeddings_2.shape}\")\n",
    "embeddings_2 = embeddings_2.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76529726-95e2-4a5c-9d9b-90994c268d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    embedding_dim = 384  \n",
    "    index = faiss.IndexFlatL2(embedding_dim)\n",
    "    all_embeddings = np.concatenate([embeddings, embeddings_2]).astype(np.float32)\n",
    "    index.add(all_embeddings)\n",
    "    all_docs = docs_processed + docs_processed_2\n",
    "    metadata = {str(i): Document(page_content=doc.page_content, metadata=doc.metadata) for i, doc in enumerate(all_docs)}\n",
    "    docstore = InMemoryDocstore(metadata)\n",
    "    index_to_docstore_id = {i: str(i) for i in range(index.ntotal)}\n",
    "    \n",
    "    # Initialize the FAISS vector store\n",
    "    VDB_l2_noisy = FAISS(\n",
    "        index=index,\n",
    "        docstore=docstore,\n",
    "        index_to_docstore_id=index_to_docstore_id,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    if Saving:\n",
    "        with open(\"PKL files/VDB_l2_noisy.pkl\", \"wb\") as f:\n",
    "            pickle.dump(VDB_l2_noisy, f)\n",
    "else:\n",
    "    with open(\"PKL files/VDB_l2_noisy.pkl\", \"rb\") as f:\n",
    "        VDB_l2_noisy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "df56fd52-29f4-4a0b-9ed2-5eac9f503256",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_pipeline_with_rerank = RAGPipeline_with_rerank(\n",
    "        model_name=\"google/flan-t5-small\",\n",
    "        retriever=VDB_l2_noisy,\n",
    "        cross_encoder_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\",\n",
    "        device=\"cpu\"  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8d48555f-5933-42ed-a8f0-5ce876c56715",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 1,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "85493e4f-a0af-4f0f-b827-3dd017d90c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers_2 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 2,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers_2.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers_2.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers_2, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers_2.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "585f0767-2c20-4a50-b840-f13e5346f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Generating:\n",
    "    triviaqa_rerank_noisy_answers_3 = []\n",
    "    \n",
    "    for i in tqdm(range(len(subset)), desc=\"Generating answers\", unit=\"question\"):\n",
    "        question = subset[i]['question']\n",
    "        answer,context = rag_pipeline_with_rerank.generate_answer(question,k_retriever=20,k_reranked = 3,return_context = True)\n",
    "        triviaqa_rerank_noisy_answers_3.append({\"id\": subset[i][\"question_id\"], \"question\": question, \"answer\": answer,'ground_truths':subset[i][\"answer\"]['aliases'],'context':context})\n",
    "    if Saving:\n",
    "        with open('PKL files/triviaqa_rerank_noisy_answers_3.pkl', 'wb') as f:\n",
    "            pickle.dump(triviaqa_rerank_noisy_answers_3, f)\n",
    "else:\n",
    "    with open('PKL files/triviaqa_rerank_noisy_answers_3.pkl', 'rb') as f:\n",
    "        triviaqa_rerank_noisy_answers_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5bba61c9-ac25-45ee-810b-98eca4615df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name =\"google/flan-t5-small\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cd671bbe-e4af-4e38-9b25-dc4b3fc902f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397a8d12385040feaaf36525143970e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 1:\n",
      "553 / 1000\n",
      "Match Score: 0.5530\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy = evaluate_answers(triviaqa_rerank_noisy_answers,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 1:')\n",
    "print(f\"{exact_matches_rerank_noisy} / 1000\")\n",
    "print(f\"Match Score: {exact_matches_rerank_noisy / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8eee6a69-04d0-4c3f-85ca-46a8c1d3c44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18afc8d00ccc405c80adb4c02a75ed1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 2:\n",
      "563 / 1000\n",
      "Match Score: 0.5630\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy_2 = evaluate_answers(triviaqa_rerank_noisy_answers_2,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 2:')\n",
    "print(f\"{exact_matches_rerank_noisy_2} / 1000\")\n",
    "print(f\"Match Score: {exact_matches_rerank_noisy_2 / 1000:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ad4e9030-f3dd-4551-82f4-fe549b87044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbdfeb70bc546048f38de10d14f1cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers:   0%|          | 0/1000 [00:00<?, ?question/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation score for RAG model with k = 3:\n",
      "558 / 1000\n",
      "Match Score: 0.5580\n"
     ]
    }
   ],
   "source": [
    "exact_matches_rerank_noisy_3 = evaluate_answers(triviaqa_rerank_noisy_answers_3,tokenizer)\n",
    "\n",
    "print('Evaluation score for RAG model with k = 3:')\n",
    "print(f\"{exact_matches_rerank_noisy_3} / 1000\")\n",
    "print(f\"Match Score: {exact_matches_rerank_noisy_3 / 1000:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
